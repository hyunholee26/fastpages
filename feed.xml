<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://hyunholee26.github.io/fastpages/feed.xml" rel="self" type="application/atom+xml" /><link href="https://hyunholee26.github.io/fastpages/" rel="alternate" type="text/html" /><updated>2022-02-22T20:34:10-06:00</updated><id>https://hyunholee26.github.io/fastpages/feed.xml</id><title type="html">Hyunho’s Blog</title><entry><title type="html">Rainfall Runoff Modeling using Recurrent Neural Network</title><link href="https://hyunholee26.github.io/fastpages/2022/02/20/Rainfall-Runoff-Modeling-using-Recurrent-Neural-Network.html" rel="alternate" type="text/html" title="Rainfall Runoff Modeling using Recurrent Neural Network" /><published>2022-02-20T00:00:00-06:00</published><updated>2022-02-20T00:00:00-06:00</updated><id>https://hyunholee26.github.io/fastpages/2022/02/20/Rainfall-Runoff-Modeling-using-Recurrent-Neural-Network</id><author><name></name></author><category term="Rainfall-Runoff Modeling" /><category term="Recurrent Neural Network" /><summary type="html"><![CDATA[1. Rainfall–runoff modelling using Long Short-Term Memory (LSTM) networks Authors : Frederik Kratzert, Daniel Klotz, Claire Brenner, Karsten Schulz, and Mathew Herrnegger Abstract : Rainfall–runoff modelling is one of the key challenges in the field of hydrology. Various approaches exist, ranging from physically based over conceptual to fully data-driven models. In this paper, we propose a novel data-driven approach, using the Long Short-Term Memory (LSTM) network, a special type of recurrent neural network. The advantage of the LSTM is its ability to learn long-term dependencies between the provided input and output of the network, which are essential for modelling storage effects in e.g. catchments with snow influence. We use 241 catchments of the freely available CAMELS data set to test our approach and also compare the results to the well-known Sacramento Soil Moisture Accounting Model (SAC-SMA) coupled with the Snow-17 snow routine. We also show the potential of the LSTM as a regional hydrological model in which one model predicts the discharge for a variety of catchments. In our last experiment, we show the possibility to transfer process understanding, learned at regional scale, to individual catchments and thereby increasing model performance when compared to a LSTM trained only on the data of single catchments. Using this approach, we were able to achieve better model performance as the SAC-SMA + Snow-17, which underlines the potential of the LSTM for hydrological modelling applications. Noteworthy parts : Figure 15 shows the evolution of a single LSTM cell (ct; see Sect. 2.1) of a trained LSTM over the period of one input sequence (which equals 365 days in this study) for an arbitrary, snow-influenced catchment. We can see that the cell state matches the dynamics of the temperature curves, as well as our understanding of snow accumulation and snowmelt. As soon as temperatures fall below 0 ∘C the cell state starts to increase (around time step 60) until the minimum temperature increases above the freezing point (around time step 200) and the cell state depletes quickly. Also, the fluctuations between time steps 60 and 120 match the fluctuations visible in the temperature around the freezing point. Thus, albeit the LSTM was only trained to predict runoff from meteorological observations, it has learned to model snow dynamics without any forcing to do so. 2. Sequence-to-Sequence Learning with Deep Neural Networks in Rainfall-Runoff Modeling in Iowa Authors : Xiang, Z., Demir, I. Abstract : Sequence-to-sequence(seq2seq) learning with deep neural networks can be used to solve complex time-series problems. This study presents an end-to-end rainfall-runoff model considering the NCEP/CPC 4km precipitation, empirical evapotranspiration, and USGS stream runoff data in watershed scale using seq2seq learning with Gated Recurrent Unit network. For each USGS station-based watershed, after calibration with appropriate input timesteps and batch size determined from the domain, the model can predict runoff for the next 120 hours with observed precipitation and runoff, empirical evapotranspiration, and forecast precipitation. For the downstream stations, we used the upstream forecast results as an additional input, which reduced the errors caused by spatial inequality of precipitation and improved the model accuracy. Final evaluation shows that, for the test water year 2018, on 126 available USGS stations in Iowa, the median of Nash-Sutcliffe model Efficiency (NSE) are 0.84, 0.77, 0.72, 0.69 and 0.67 for the prediction of 24th, 48th, 72nd, 96th and 120th hour, while the stream persistences are 0.74, 0.40, 0.11, -0.02 and -0.15 respectively. 98 out of 126 stations have an acceptable 120th-hour prediction NSE value over 0.50. The results show strong predictive power and could be used to improve forecast accuracy in short-term flood forecast applications. This study also demonstrates a strong potential of applying seq2seq learning on time-series tasks in hydrology and earth science studies. Noteworthy parts : For each USGS station-based watershed, after calibration with appropriate input timesteps and batch size determined from the domain, the model can predict runoff for the next 120 hours with observed precipitation and runoff, empirical evapotranspiration, and forecast precipitation. For the downstream stations, we used the upstream forecast results as an additional input, which reduced the errors caused by spatial inequality of precipitation and improved the model accuracy. 3. A Rainfall-Runoff Model With LSTM-Based Sequence-to-Sequence Learning Authors : Zhongrun Xiang, Jun Yan, Ibrahim Demir Abstract : Rainfall-runoff modeling is a complex nonlinear time series problem. While there is still room for improvement, researchers have been developing physical and machine learning models for decades to predict runoff using rainfall data sets. With the advancement of computational hardware resources and algorithms, deep learning methods such as the long short-term memory (LSTM) model and sequence-to-sequence (seq2seq) modeling have shown a good deal of promise in dealing with time series problems by considering long-term dependencies and multiple outputs. This study presents an application of a prediction model based on LSTM and the seq2seq structure to estimate hourly rainfall-runoff. Focusing on two Midwestern watersheds, namely, Clear Creek and Upper Wapsipinicon River in Iowa, these models were used to predict hourly runoff for a 24-hr period using rainfall observation, rainfall forecast, runoff observation, and empirical monthly evapotranspiration data from all stations in these two watersheds. The models were evaluated using the Nash-Sutcliffe efficiency coefficient, the correlation coefficient, statistical bias, and the normalized root-mean-square error. The results show that the LSTM-seq2seq model outperforms linear regression, Lasso regression, Ridge regression, support vector regression, Gaussian processes regression, and LSTM in all stations from these two watersheds. The LSTM-seq2seq model shows sufficient predictive power and could be used to improve forecast accuracy in short-term flood forecast applications. In addition, the seq2seq method was demonstrated to be an effective method for time series predictions in hydrology.]]></summary></entry><entry><title type="html">Rainfall Runoff Modeling using Graph Neural Network</title><link href="https://hyunholee26.github.io/fastpages/2022/02/20/Rainfall-Runoff-Modeling-using-Graph-Neural-Network.html" rel="alternate" type="text/html" title="Rainfall Runoff Modeling using Graph Neural Network" /><published>2022-02-20T00:00:00-06:00</published><updated>2022-02-20T00:00:00-06:00</updated><id>https://hyunholee26.github.io/fastpages/2022/02/20/Rainfall-Runoff-Modeling-using-Graph-Neural-Network</id><author><name></name></author><category term="Graph Neural Network" /><category term="Rainfall-Runoff Modeling" /><summary type="html"><![CDATA[1. High-resolution rainfall-runoff modeling using graph neural network Authors : Zhongrun Xiang, Ibrahim Demir Abstract : Time-series modeling has shown great promise in recent studies using the latest deep learning algorithms such as LSTM (Long Short-Term Memory). These studies primarily focused on watershed-scale rainfall-runoff modeling or streamflow forecasting, but the majority of them only considered a single watershed as a unit. Although this simplification is very effective, it does not take into account spatial information, which could result in significant errors in large watersheds. Several studies investigated the use of GNN (Graph Neural Networks) for data integration by decomposing a large watershed into multiple sub-watersheds, but each sub-watershed is still treated as a whole, and the geoinformation contained within the watershed is not fully utilized. In this paper, we propose the GNRRM (Graph Neural Rainfall-Runoff Model), a novel deep learning model that makes full use of spatial information from high-resolution precipitation data, including flow direction and geographic information. When compared to baseline models, GNRRM has less over-fitting and significantly improves model performance. Our findings support the importance of hydrological data in deep learning-based rainfall-runoff modeling, and we encourage researchers to include more domain knowledge in their models. 2. Fully distributedrainfall-runoff modeling using spatial-temporal graph neural network Authors : Zhongrun Xiang, Ibrahim Demir Abstract : Recent studies using latest deep learning algorithms such as LSTM (Long Short-Term Memory) have shown great promise in time-series modeling. There are many studies focusing on the watershed-scale rainfall-runoff modeling or streamflow forecasting, often considering a single watershed with limited generalization capabilities. To improve the model performance, several studies explored an integrated approach by decomposing a large watershed into multiple sub-watersheds with semi-distributed structure. In this study, we propose an innovative physics-informed fully-distributed rainfall-runoff model, NRM-Graph (Neural Runoff Model-Graph), using Graph Neural Networks (GNN) to make full use of spatial information including the flow direction and geographic data. Specifically, we applied a time-series model on each grid cell for its runoff production. The output of each grid cell is then aggregated by a GNN as the final runoff at the watershed outlet. The case study shows that our GNN based model successfully represents the spatial information in predictions. NRM-Graph network has shown less over-fitting and a significant improvement on the model performance compared to the baselines with spatial information. Our research further confirms the importance of spatially distributed hydrological information in rainfall-runoff modeling using deep learning, and we encourage researchers to incorporate more domain knowledge in modeling. 3. Large-scale river network modeling using Graph Neural Networks Authors : Frederik Kratzert, Daniel Klotz, Martin Gauch, Christoph Klingler, Grey Nearing, and Sepp Hochreiter Abstract : In the recent past, several studies have demonstrated the ability of deep learning (DL) models, especially based on Long Short-Term Memory (LSTM) networks, for rainfall-runoff modeling. However, almost all of these studies were limited to (multiple) individual catchments or small river networks, consisting of only a few connected catchments. In this study, we investigate large-scale, spatially distributed rainfall-runoff modeling using DL models. Our setup consists of two independent model components: One model for the runoff-generation process and one for the routing. The former is an LSTM-based model that predicts the discharge contribution of each sub-catchment in a river network. The latter is a Graph Neural Network (GNN) that routes the water along the river network network in hierarchical order. The first part is set up to simulate unimpaired runoff for every sub-catchment. Then, the GNN routes the water through the river network, incorporating human influences such as river regulations through hydropower plants. The main focus is to investigate different model architectures for the GNN that are able to learn the routing task, as well as potentially accounting for human influence. We consider models based on 1D-convolution, attention modules, as well as state-aware time series models.The decoupled approach with individual models for sub-catchment discharge prediction and routing has several benefits: a) We have an intermediate output of per-basin discharge contributions that we can inspect. b) We can leverage observed streamflow when available. That is, we can optionally substitute the discharge simulations of the first model with observed discharge, to make use of as much observed information as possible. c) We can train the model very efficiently. d) We can simulate any intermediate node in the river network, without requiring discharge observations.For the experiments, we use a new large-sample dataset called LamaH (Large-sample Data for Hydrology in Central Europe) that covers all of Austria and the foreign upstream areas of the Danube. We consider the entire Danube catchment upstream of Bratislava, a highly diverse region, including large parts of the Alps, that covers a total area of more than 130000km2. Within that area, LamaH contains hourly and daily discharge observations for more than 600 gauge stations. Thus, we investigate DL-based routing models not only for daily discharge, but also for hourly discharge.Our first results are promising, both daily and hourly discharge simulation. For example, the fully DL-based distributed models capture the dynamics as well as the timing of the devastating 2002 Danube flood. Building upon our work on learning universal, regional, and local hydrological behaviors with machine learning, we try to make the GNN-based routing as universal as possible, striving towards a globally applicable, spatially distributed, fully learned hydrological model. ppt slide]]></summary></entry><entry><title type="html">A Comprehensive Survey on Graph Neural Networks</title><link href="https://hyunholee26.github.io/fastpages/2022/02/20/A-Comprehensive-Survey-on-Graph-Neural-Networks.html" rel="alternate" type="text/html" title="A Comprehensive Survey on Graph Neural Networks" /><published>2022-02-20T00:00:00-06:00</published><updated>2022-02-20T00:00:00-06:00</updated><id>https://hyunholee26.github.io/fastpages/2022/02/20/A-Comprehensive-Survey-on-Graph-Neural-Networks</id><author><name></name></author><category term="Graph Neural Network" /><summary type="html"><![CDATA[0. Paper Link A Comprehensive Survey on Graph Neural Networks 1. Background This paper will be summarized after reviewing…]]></summary></entry><entry><title type="html">Regarding Deep learning with Uncertainty Estimation</title><link href="https://hyunholee26.github.io/fastpages/2022/02/13/Regarding-Deep-learning-with-Uncertainty-Estimation.html" rel="alternate" type="text/html" title="Regarding Deep learning with Uncertainty Estimation" /><published>2022-02-13T00:00:00-06:00</published><updated>2022-02-13T00:00:00-06:00</updated><id>https://hyunholee26.github.io/fastpages/2022/02/13/Regarding-Deep-learning-with-Uncertainty-Estimation</id><author><name></name></author><category term="uncertainty estimation" /><summary type="html"><![CDATA[I will summarize serveral articles regarding deep learning with uncertainty estimation. Providing confidence intervals in regression problems is related to uncertainty estimation. A phrase that can express this well is quoted as follows. We do a lot of regression, with everything from random forests to recurrent neural networks. And as good as our models are, we know they can never be perfect. Therefore, whenever we provide our customers with predictions, we also like to include a set of confidence intervals: what range around the prediction will the actual value fall within, with (e.g.) 80% confidence? 1. A guide to generating probability distributions with neural networks This article give the example code related to generate distribution of predicted value with cumstomed layer and loss function. 2. How to generate neural network confidence intervals with Keras This article suggests same notion and implementation with Monte Carlo Dropout. Also, it gives the way to calculate optimal dropout rate.]]></summary></entry><entry><title type="html">Building own blog with Jekyll and Github in 20 minutes</title><link href="https://hyunholee26.github.io/fastpages/github/jekyll/2022/02/06/Building-own-blog-with-jekyll-and-github-in-20-minutes.html" rel="alternate" type="text/html" title="Building own blog with Jekyll and Github in 20 minutes" /><published>2022-02-06T00:00:00-06:00</published><updated>2022-02-06T00:00:00-06:00</updated><id>https://hyunholee26.github.io/fastpages/github/jekyll/2022/02/06/Building-own-blog-with-jekyll-and-github-in-20-minutes</id><author><name></name></author><category term="github" /><category term="jekyll" /><summary type="html"><![CDATA[Building own blog with Jekyll and Github in 20 minutes]]></summary></entry></feed>