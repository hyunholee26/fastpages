<p>I will summarize serveral articles regarding deep learning with uncertainty estimation. Providing confidence intervals in regression problems is related to uncertainty estimation. A phrase that can express this well is quoted as follows.</p>

<blockquote>
  <p>We do a lot of regression, with everything from random forests to recurrent neural networks. And as good as our models are, we know they can never be perfect. Therefore, whenever we provide our customers with predictions, we also like to include a set of confidence intervals: what range around the prediction will the actual value fall within, with (e.g.) 80% confidence?</p>
</blockquote>

<h2 id="1-a-guide-to-generating-probability-distributions-with-neural-networks">1. <a href="https://medium.com/hal24k-techblog/a-guide-to-generating-probability-distributions-with-neural-networks-ffc4efacd6a4">A guide to generating probability distributions with neural networks</a></h2>
<ul>
  <li>This article give the example code related to generate distribution of predicted value with cumstomed layer and loss function.</li>
</ul>

<h2 id="2-how-to-generate-neural-network-confidence-intervals-with-keras">2. <a href="https://medium.com/hal24k-techblog/how-to-generate-neural-network-confidence-intervals-with-keras-e4c0b78ebbdf">How to generate neural network confidence intervals with Keras</a></h2>
<ul>
  <li>This article suggests same notion and implementation with <a href="https://towardsdatascience.com/monte-carlo-dropout-7fd52f8b6571">Monte Carlo Dropout</a>. Also, it gives the way to calculate optimal dropout rate.</li>
</ul>

