{
  
    
        "post0": {
            "title": "PRML 훑어보기",
            "content": "1.1 Example: Polynomial Curve Fitting . 모델의 파라메터수, 데이터 수, regularization term이 모델에 미치는 영향에 대해 예를 들어 살펴봄 모델의 파라메터수가 많아지면 overfitting이 될 수 있음 | 데이터수가 많아지면 overfitting을 막을 수 있음 | regularization term의 변수에 따라 모델이 overfitting될 수 도 있고, underfitting될 수도 있음. 즉 fitting 정도를 조절할 수 있음. | . | 이후 MLE, MAP 등에서 모양을 조금씩 바꾸며 계속 이 예제가 등장함 | . 1.2 Probability Theory . Sum rule, production rule을 예를 들어 설명함 | Probability density, Expectations 및 Covariance를 설명함 | prior, likelihood, posterior를 설명함 빈도주의자는 관찰된 데이터를 가장 잘표현하는 파라메터를 찾는다면(MLE), | 베이지안은 믿음(사전지식, prior)에서 데이터가 관찰될때마다 그것을 조금씩 갱신하는 방식임 | posterior는 prior와 likelihood의 곱에 비례하며, 데이터가 갱신될 때마다, posterior는 prior에서 likelihood로 점차 변화함 | 다만 베이지안은 계산상의 편의를 위해(prior와 likelihood를 곱해야하므로) conjugacy 관계인 분포가 많이 사용됨 | . | gaussian distribution을 설명함, MLE 방식으로 gaussian distribution의 variance를 구하면, $ frac{N-1}{n}$만큼 bias 됨 | 앞서 나왔던 커브피팅 문제에서 관측데이터와 예측데이터의 차이(error 또는 residual)가 gaussian distribution을 따른다고 가정하고, MAP를 최소로 하는 해를 구하면, 그것은 ridge regression의 해를 구하는 형태와 동일해짐 | . | 베이지안 인퍼런스를 위해서는 prediction distribution을 구해야함, prediction distribution은 production rule에 의해 likelihood와 posterior(갱신된 prior)의 곱으로 표현되며, posterior가 gaussian distribution인 경우, prediction distribution을 gaussian form으로 정리하면 | gausssian process 형태인( $N(t mid m(x), s^2(x)$ )로 정리됨 | 즉, bayesian infrerence를 위해 구한 prediction distribution은 gaussian process로 표현됨. | . | . 2.1 binary variable . Conjugate Prior : A prior is conjugate for the likelihood function if the posterior is of the sam form as the prior. | binomial 분포와 beta분포, bernuii 분포와 beta분포는 각각 conjugacy임 | . 2.2 multinomial variable . multinomial distribution과 Dirichlet distribution은 conjugacy임 | . 2.3 Gaussian Distribution . multivariate gaussian distribution form에서 exp의 지수파트를 mahalanobis distance라고 하며, $ Sigma$가 Identity Matrix일때, 유클리언 디스턴스가 됨 | . | 가우시안 분포는 중심극한정리에 쓰임(데이터 갯수가 커질수록 분포의 평균이 가우시안 분포에 가까워짐) | spectral theorem을 보임, 이것은 이후 multivariate gaussian distribution의 mean과 variance를 증명하는데 사용됨 | 데이터의 수가 많아지면, mean으로 D개, covariance matrix의 요소로 $D(D+1)/2$ 개의 파라메터를 가짐(symmetric이므로), 행렬사이즈가 quadratically하게 증가하니까 계산량도 많아지고, 역행렬 구하는것도 어려워짐 | 그래서 $ Sigma = diag( sigma_i^2)$ 놓거나(probability density contour 그림을 그리면 coordinate axie방향으로만 ellipse가 그려짐, 제한된 방향성을 가진다는 의미임) | 또는 더 제한해서 $ Sigma = sigma^2I$로 할 수 있음. 이때는 모든 대각행렬이 같은 값을 가지므로 동그란 모양으로 나타나고, 이것을 isotropic covariance라고 한다. (방향성이 없고, 거리만 관계가 있음) | 빠른 계산과 데이터간의 관계의 특징을 잡아내는 것은 trade off 관계임 | . | 또한 gaussian distribution은 multimodal distribution을 표현하는데 한계가 있음. 그래서 gaussian mixture model을 이후에 배울 것임 | (8장에서 다룬다고 함, 추가로 살펴볼것!) For instance, the Gaussian version of the Markov random field, which is widely used as a probabilistic model of images, is a Gaussian distribution over the joint space of pixel intensities but rendered tractable through the imposition of considerable structure reflecting the spatial organization of the pixels | joint distribution $p(x_a, x_b)$ is Gaussian, then the conditional distribution $p(x_a | x_b)$ will again be Gaussian. 시간관계상(?) 증명은 이해는 하지 못하고 그냥 받아들임. | . | marginal gaussian distribution( $p(x_a) = int p(x_a, x_b) dx_b$ )도 gaussian distribution임 | Gaussian variable에 대한 bayes theorem과 gaussian에 대한 MLE를 유도함. 시간관계상 이해하지 않고 받아들임. | 데이터가 특정 시간마다 업데이트 되는 경우, N번째 mean의 MLE는 N-1까지의 mean에 새로 업데이트 된 데이터와 N-1까지 mean의 차이에 대해 1/N만큼 반영한다. N이 커질수록, 차이가 동일한 경우, 업데이트 되는 값의 크기가 작아지게된다. | Bayesian관점으로 Gaussian 분포에서 분산을 알고, 평균을 추정해야하는 경우(MAP), posterior의 평균은 prior의 평균과 likelihood의 평균사이에 존재한다. $N = 0$이면, prior의 mean이 되고, $N rightarrow infty$이면 maximum likelihood의 mean이 된다. 분산은 $N=0$인 경우, prior의 분산을 따르며, $N rightarrow infty$이면 0이 되고 posterior분포는 maximum likelihood의 평균값에서 무한대의 값을(분산 = 0) 표현하는 분포가 된다. | 평균을 알고 분산을 모르는 경우, 평균과 분산을 모두 모르는 경우에 대해 각각 gaussian 분포에서 MAP방식으로 mean과 variance를 추정하는 법을 다룬다. | . 3.1 Linear Basis Function Model . basis function( $ phi(x)$ )을 적용한 형태로 linear model을 정의함 y(x,w)=w0+∑j=1M−1wjϕj(x)y(x, w) = w_0 + sum_{j=1}^{M-1}w_j phi_j(x)y(x,w)=w0​+∑j=1M−1​wj​ϕj​(x) | basis function으로 non-linear function을 사용함으로써 비선형적 feature들을 모델이 표현할 수 있음, w에 대해 선형 모형이므로 linear 모델이라고 부름 | chapter1에서 나온 예제는 $ phi(x)_j = x^j$ 인 경우임 | 모형의 예측값과 실제값의 차이가 gaussian distribution을 따른다고 가정하고, MLE로 평균을 추정하면, wML=(ΦTΦ)−1ΦTtw_{ML} = ( Phi^T Phi)^{-1} Phi^TtwML​=(ΦTΦ)−1ΦTt | 이며, 이것을 normal equations for the least squares problem이라고 함. $ Phi$는 design matrix라고 함 | . 3.3 Bayesian Linear Regression . | .",
            "url": "https://hyunholee26.github.io/fastpages/statistics/2022/09/14/A-quick-look-at-PRML.html",
            "relUrl": "/statistics/2022/09/14/A-quick-look-at-PRML.html",
            "date": " • Sep 14, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Hierarchical Modeling and Analysis for Spatial Data (Chap2) - (작성중)",
            "content": "",
            "url": "https://hyunholee26.github.io/fastpages/spatial%20statistics/2022/09/07/Hierarchical-Modeling-and-Analysis-for-Spatial-Data-Chap2.html",
            "relUrl": "/spatial%20statistics/2022/09/07/Hierarchical-Modeling-and-Analysis-for-Spatial-Data-Chap2.html",
            "date": " • Sep 7, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Gaussian Process and Gaussian Process Regression",
            "content": "0. 들어가며 . Spatiotemporal Analysis를 수강하면서, Gaussian Process를 공부하기 위해 참고사이트의 내용을 다시 정리한 글입니다. 대부분의 내용은 참고한 사이트를 따르며, 일부 제가 이해한 내용을 추가적으로 작성하였습니다. . 참고자료 https://pasus.tistory.com/209?category=1287736 | Pattern Recognition and Machine Learning | . | . 1. Gaussian Process . 가우시안 프로세스(GP, Gaussian process)는 프로세스 집합 내에 있는 랜덤변수들의 임의의 조합이 모두 결합(joint) 가우시안 분포를 갖는 랜덤 프로세스로 정의된다. . 예를 들어서 인덱스 $x_1, x_2, cdots, x_n$에 해당하는 랜덤변수가 $f_i = f(x_i)$ 일 때, 이로부터 가능한 모든 부분 집합 ${f_1}, {f_2, f_3}, cdots, {f_1, f_2, cdots f_m}$ 이 모두 결합 가우시안 분포(joint gaussian distribution)를 갖는 프로세스이다. | 달리 설명하자면, $f_1$ 을 성분으로 하는 벡터 $f_{1:m} = [f_1, f_2, cdots, f_m]^T$가 가우시안 랜덤벡터인 프로세스이다. 여기서 $m$ 은 프로세스에서 임의로 선정한 인덱스의 갯수이므로, 가우시안 랜덤벡터는 무한 차원을 가질 수 있다. 즉 가우시안 프로세스는 가우시안 랜덤벡터를 무한 차원으로 확장한 것으로 설명할 수도 있겠다. | . 가우시안 분포의 특성을 평균과 공분산으로 표현하듯이 가우시안 프로세스도 평균함수 $ mu(x)$ 와 공분산 $k(x,x’)$ 로 특징지울 수 있다. . f(x)∼GP(μ(x),k(x,x′))f(x) sim GP( mu(x), k(x, x&amp;#x27;))f(x)∼GP(μ(x),k(x,x′)) . 여기서 공분산 $k(x,x’)$ 는 다음과 같다. . k(x,x′)=E[(f(x)−μ(x))(f(x′)−μ(x′))]k(x,x&amp;#x27;) = E[(f(x) - mu(x))(f(x&amp;#x27;) - mu(x&amp;#x27;))]k(x,x′)=E[(f(x)−μ(x))(f(x′)−μ(x′))] .",
            "url": "https://hyunholee26.github.io/fastpages/statistics/2022/09/06/Gaussian-Process-and-Gaussian-Process-Regression.html",
            "relUrl": "/statistics/2022/09/06/Gaussian-Process-and-Gaussian-Process-Regression.html",
            "date": " • Sep 6, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Gaussian Process Regression 이해를 위한 기초지식",
            "content": "0. 들어가며 . Spatiotemporal Analysis를 수강하면서, Gaussian Process Regression 이해하기 위해 필요한 지식들을 정리한 글입니다. . 참고자료 : Pattern Recognition and Machine Learning | 이 책의 chpater1 ~ 6을 읽고 Gaussian Process regression을 이해하기 위해 필요한 기초지식들을 다시 정리하였습니다. | . 1. Probability . Sample space: the sample space of an experiment or random trial is the set of all possible outcomes or results of that experiment. An event is a subset of the sample space. 동전을 던졌을 때 나올 수 있는 결과는 앞면(H) 또는 뒷면(T)임, 발생할 수 있는 모든 경우의 수를 의미함. . | Random Variable: A Random Variable is a mathematical formalization of a quantity or object which depends on random events. It is a mapping or a function from possible outcomes in a sample space to a measurable space, often the real numbers. (random variable이란 sample space(모든경우의 수)와 probability(확률값, 발생가능한 값들의 영역의 넓이)의 맵핑(함수)으로 이해함) . | Probability: The probability of an event A is the sum of the probabilities of the individual outcomes of which it is composed. It is denoted P(A). . | . 2. Conditional probability . In probability theory, conditional probability is a measure of the probability of an event occurring, given that another event (by assumption, presumption, assertion or evidence) has already occurred. . P(A∣B)=P(A∩B)P(B)P(A mid B) = frac{P( A cap B)}{P(B)}P(A∣B)=P(B)P(A∩B)​ . Independence(독립) : Two events A and B are independent if and only if their joint probability equals the product of their probabilities . P(A∩B)=P(A)⋅P(B)P(A cap B) = P(A) cdot P(B)P(A∩B)=P(A)⋅P(B) . 조건부 확률에서 P(A)와 P(B)가 독립인 경우, $P(A mid B) = frac{P( A cap B)}{P(B)} = frac{P(A) cdot P(B)}{P(B)} = P(A)$가 성립하며, 조건부 확률로 사건A에 대해 사건B가 주어지는 경우와 주어지지 않는 경우의 확률이 같은 경우를 의미하는 것으로 이해할 수 있다. 또한 다른 말로 표현해보면, 전체에서 A가 발생할 확률과 사건B가 발생했을 때 사건A가 발생할 확률이 같은 경우를 의미하는 것으로도 이해할 수 있다. (독립인 경우, $P(A) cap P(B) neq 0$임) | . 3. Bayes’s Theorem . Bayes’ theorem is stated mathematically as the following equation: | . P(A∣B)=P(B∣A)⋅P(A)P(B),where P(B)≠0.P(A mid B) = frac {P(B mid A) cdot P(A)} {P(B)}, where space P(B) neq 0.P(A∣B)=P(B)P(B∣A)⋅P(A)​,where P(B)=0. . Bayes’s Theorem은 conditonal probability로 부터 유도됩니다. | . P(A∣B)=P(A∩B)P(B), then P(A∩B)=P(A∣B)⋅P(B)P(A mid B) = frac{P( A cap B)}{P(B)}, space then space P(A cap B) = P(A mid B) cdot P(B)P(A∣B)=P(B)P(A∩B)​, then P(A∩B)=P(A∣B)⋅P(B) . P(B∣A)=P(A∩B)P(A), then P(A∩B)=P(B∣A)⋅P(A)P(B mid A) = frac{P( A cap B)}{P(A)}, space then space P(A cap B) = P(B mid A) cdot P(A)P(B∣A)=P(A)P(A∩B)​, then P(A∩B)=P(B∣A)⋅P(A) . hence,P(A∣B)⋅P(B)=P(B∣A)⋅P(A)hence, P(A mid B) cdot P(B) = P(B mid A) cdot P(A)hence,P(A∣B)⋅P(B)=P(B∣A)⋅P(A) . 4. Bayes’s Theorem 예제 . 우리나라 사람이 폐암에 걸릴 확률은 3%이고, 폐암을 99% 양성으로 진단하는 시약이 있다. 이 시약으로 폐암을 진단했을 때 양성반응을 보인 경우, 실제 폐암에 걸렸을 확률은 얼마인가? . | 구해야할 확률과 문제에서 주어진 확률을 구분해보면, . 우리가 구해야할 확률 : $P(폐암 mid 양성)$ | 문제에서 주어진 확률은, | . | . P(폐암)=0.03 (⇒P(정상)=0.97),P(폐암) = 0.03 space ( Rightarrow P(정상) = 0.97),P(폐암)=0.03 (⇒P(정상)=0.97), . P(양성∣폐암)=0.99 (⇒P(양성∣정상)=0.01)P(양성 mid 폐암) = 0.99 space ( Rightarrow P(양성 mid 정상) = 0.01)P(양성∣폐암)=0.99 (⇒P(양성∣정상)=0.01) . $P(폐암 mid 양성)$을 직접 계산할 수 없기 때문에, Bayes’s theorem을 이용하면, | . P(폐암∣양성)=P(양성∣폐암)⋅P(폐암)/P(양성)P(폐암 mid 양성) = P(양성 mid 폐암) cdot P(폐암) / P(양성)P(폐암∣양성)=P(양성∣폐암)⋅P(폐암)/P(양성) . P(양성)=P(양성∣정상)⋅P(정상)+P(양성∣폐암)⋅P(폐암)P(양성) = P(양성 mid 정상) cdot P(정상) + P(양성 mid 폐암) cdot P(폐암)P(양성)=P(양성∣정상)⋅P(정상)+P(양성∣폐암)⋅P(폐암) . 이며, 이를 계산하면, $P(양성) = 0.01 * 0.97 + 0.99 * 0.03 = 0.03939109$ . | 따라서 $P(폐암 mid 양성) = 0.99 * 0.03 / 0.03939109 = 0.7539776127037866$ 이며, 약 75%임. . | . 5. Likelihood vs. Probability . Likelihood는 가능도로 번역됩니다. 저에게 Probability와 Likelihood는 다소 헷갈리는 개념인데요, 저는 통계를 깊이있게 공부하는 사람은 아니기 때문에 이 지식을 사용하기 위한 목적으로만 있는 그대로 표현해보겠습니다. | Binomial distribution의 pmf를 예로 들겠습니다. 이 pmf는 n은 전체시행횟수, k는 이벤트발생횟수, $ theta$가 1회 시행시 발생확률을 매개변수로 하는 함수식입니다. | . Pr⁡(K=k)=f(k,n,θ)=(nk)θk(1−θ)n−k Pr(K = k) = f(k,n, theta)={n choose k} theta^k(1- theta)^{n-k}Pr(K=k)=f(k,n,θ)=(kn​)θk(1−θ)n−k . (Probability) 우리가 믿고 있는 1회 시행시 발생확률 $ theta$ 가 주어지고, 사건이 발생했을 때(n과 k가 관찰됨), pmf를 계산한 값입니다. 이 경우, pmf는 n가 k를 매개변수로 가지는 함수식이 되며, $ sum_k^{n} f(k,n, theta) = 1$입니다. 다시 표현하면, $ theta$가 주어지고, data가 관찰되었을 때, data가 발생할 확률을 구하는 것이며, 발생가능한 모든 data의 확률의 합은 1이 됩니다. . | (Likelihood) 사건이 발생했을 때(n과 k가 관찰됨), 1회 시행시 발생확률 $ theta$ 에 따른 pmf를 계산한 값입니다. 이것은 $ theta$에 따른 사건의 발생가능도를 계산한 것으로 표현할 수 있습니다. 이 경우, pmf는 $ theta$를 매개변수로 가지는 함수식이 되며, $ sum_{ theta} f(k,n, theta)$는 반드시 1은 아닙니다. . | 최종 정리를 해보면, pmf에 대해 $ theta$가 주어지고, n과 k가 변수인 경우를 확률이라고 하며, 이때는 모든 n과 k에 대한 f(n,k)의 합은 1이됩니다. pmf에 대해 n과 k가 주어지고, $ theta$ 가 변수인 경유를 가능도라고 하며, 이때 모든 $ theta$에 대한 f( $ theta$ )의 합은 꼭 1이 되지 않습니다. 확률과 가능도는 동일한 pmf에 대해 어떤 매개변수를 pmf라는 함수의 변수로 볼 것인지에 따라 달라지는 개념이라고 최종적으로 이해했습니다. . | . 6. Maximum likelihood estimation(MLE) . In statistics, maximum likelihood estimation (MLE) is a method of estimating the parameters of an assumed probability distribution, given some observed data. This is achieved by maximizing a likelihood function so that, under the assumed statistical model, the observed data is most probable. The point in the parameter space that maximizes the likelihood function is called the maximum likelihood estimate. – From wikipedia . MLE는 주어진 관측데이터( $x_1, x_2, dots, x_n$ )에 대해, 어떠한 분포를 가정했을 때, 관측데이터와 가장 유사한 분포를 만드는 파라메터( $ theta$ )를 추정하는 방법입니다. | We pick the distribution family p(·), but don’t know the parameter θ | MLE를 수식으로 표현하면 아래와 같습니다. | . θ^MLE=argmax⁡θp(x1,x2,…,xn∣θ) hat theta_{MLE} = underset{ theta}{ operatorname{argmax}} p(x_1, x_2, dots, x_n mid theta)θ^MLE​=θargmax​p(x1​,x2​,…,xn​∣θ) . Assume data is independent and identically distributed (iid). This is written | . xi∼i.i.dp(x∣θ),i=1,…,nx_i overset{i.i.d}{ sim} p(x mid theta), i = 1, dots, nxi​∼i.i.dp(x∣θ),i=1,…,n . Writing the density as $p(x mid θ)$, then the joint density decomposes as | . p(x1,x2,…,xn∣θ)=∏i=1np(xi∣θ)p(x_1, x_2, dots, x_n mid theta) = prod_{i=1}^n p(x_i mid theta)p(x1​,x2​,…,xn​∣θ)=i=1∏n​p(xi​∣θ) . 그리고 다음과 같이 Maximum Likelihood가 되는 파라메터(θ)를 추정할 수 있습니다. | . ∇θp(x1,x2,…,xn∣θ)=∇θ∏i=1np(xi∣θ)=0 nabla_{ theta} p(x_1, x_2, dots, x_n mid theta) = nabla_{ theta} prod_{i=1}^n p(x_i mid theta) = 0∇θ​p(x1​,x2​,…,xn​∣θ)=∇θ​i=1∏n​p(xi​∣θ)=0 . Logarithm tric : It is complicated to calcuate it directly. So we use the fact that the logarithm is monotonically increasing on R+, and the equality | . argmax⁡θg(y)=argmax⁡θln(g(y)) underset{ theta}{ operatorname{argmax}} g(y) = underset{ theta}{ operatorname{argmax}} ln(g(y))θargmax​g(y)=θargmax​ln(g(y)) . ln(∏ifi)=∑iln(fi)ln( prod_i f_i) = sum_i ln(f_i)ln(i∏​fi​)=i∑​ln(fi​) . 데이터 특징에 따라 선택할 수 있는 분포들은 binomial, poisson, gaussian 등이 있습니다. | . 7. MLE 예제 . 공장에서 10개의 제품을 검사했을 때, 정상이 8개, 불량이 2개인 경우가 관측되었습니다. 이 경우, 우리는 binomial distribution을 가정할 수 있습니다. binomial distribution의 pmf는 다음과 같이 정의됩니다. | . Pr⁡(K=k)=f(k;n,θ)=(nk)θk(1−θ)n−k Pr(K = k) = f(k;n, theta)={n choose k} theta^k(1- theta)^{n-k}Pr(K=k)=f(k;n,θ)=(kn​)θk(1−θ)n−k . 파라메터 θ를 MLE로 추정해보면, | . ∇θ∏i=1np(xi∣θ)=∇θln(∏i=1np(xi∣θ))=∇θln((nk)θk(1−θ)n−k)=0 nabla_{ theta} prod_{i=1}^n p(x_i mid theta) = nabla_{ theta} ln( prod_{i=1}^n p(x_i mid theta)) = nabla_{ theta} ln({n choose k} theta^k(1- theta)^{n-k}) = 0∇θ​i=1∏n​p(xi​∣θ)=∇θ​ln(i=1∏n​p(xi​∣θ))=∇θ​ln((kn​)θk(1−θ)n−k)=0 . ∇θln(θk(1−θ)n−k)=∇θk⋅ln(θ)+(n−k)⋅ln(1−θ)=kθ−n−k1−θ=0 nabla_{ theta} ln( theta^k(1- theta)^{n-k}) = nabla_{ theta} k cdot ln( theta) + (n-k) cdot ln(1- theta) = displaystyle frac{k}{ theta} - frac{n-k}{1- theta} = 0∇θ​ln(θk(1−θ)n−k)=∇θ​k⋅ln(θ)+(n−k)⋅ln(1−θ)=θk​−1−θn−k​=0 . k(1−θ)−θ(n−k)=0k(1- theta) - theta(n-k) = 0k(1−θ)−θ(n−k)=0 . θ=kn theta = displaystyle frac{k}{n}θ=nk​ . MLE를 통해 불량확률에 파라메터는 θ는, n = 10, k = 2인 경우, 0.2로 추정할 수 있습니다. | multivariate gaussian distribution에 MLE를 적용하면, mean과 covariance는 각각 아래와 같습니다.(계산유도과정은 생략합니다) | . μ^MLE=1n∑i=1nxi, σ^MLE=1n∑i=1n(xi−μ^MLE)(xi−μ^MLE)T hat mu_{MLE} = frac{1}{n} sum_{i=1}^n x_i, space hat sigma_{MLE} = frac{1}{n} sum_{i=1}^n (x_i - hat mu_{MLE})(x_i - hat mu_{MLE})^Tμ^​MLE​=n1​i=1∑n​xi​, σ^MLE​=n1​i=1∑n​(xi​−μ^​MLE​)(xi​−μ^​MLE​)T . MLE는 데이터를 관찰하고, 관찰된 데이터를 가장 잘 표현하는 매개변수( $ theta$ )를 추정하는 방식입니다. 하지만, 관찰된 데이터는 전체 모집단을 잘 표현할 수 있는 데이터여야 할 것입니다. 그렇지 않다면, MLE로 추정된 변수로 만들어진 모델은 overfitting될 가능성이 높습니다. MLE는 빈도주의자들의 방식이라고 합니다. If $x_1, dots x_n$ don’t “capture the space” well, $ theta_{MLE}$ can overfit the data. | . | . 8. Gaussian Distribution . 분포가 가지는 계산의 편리함으로 인해, Bayesian 방법론에서는 Gaussian distribution을 많이 다룹니다. | . 8-1. Univariate Gaussian Distribution . In statistics, a normal distribution (also known as Gaussian, Gauss, or Laplace–Gauss distribution) is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function is | . f(x)=1σ2πe−12(x−μσ)2f(x) = frac {1}{ sigma sqrt{2 pi}} e ^ {- frac{1}{2}( frac{x- mu}{ sigma})^2}f(x)=σ2π . ​1​e−21​(σx−μ​)2 . random variable X is normally distributed with mean $ mu$ and standard deviation $ sigma$, one may write $ displaystyle X sim { mathcal {N}}( mu , sigma ^{2})$ | . 8-2. Multivariate Gaussian Distribution . The multivariate normal distribution of a k-dimensional random vector $X =(X_{1}, dots ,X_{k})^{T}$ can be written in the following notation: | . X∼Nk(μ,Σ),X sim { mathcal {N}}_{k} ({ boldsymbol { mu }},{ boldsymbol { Sigma }}),X∼Nk​(μ,Σ), . with k-dimensional mean vector | . μ=E⁡[X]=(E⁡[X1],E⁡[X2],…,E⁡[Xk])T,{ boldsymbol { mu }= operatorname {E} [ mathbf {X} ]=( operatorname {E} [X_{1}], operatorname {E} [X_{2}], ldots , operatorname {E} [X_{k}])^{ textbf {T}},}μ=E[X]=(E[X1​],E[X2​],…,E[Xk​])T, . and k x k covariance matrix | . Σi,j=E⁡[(Xi−μi)(Xj−μj)]=Cov⁡[Xi,Xj], Sigma_{i,j}= operatorname {E} [(X_{i}- mu _{i})(X_{j}- mu _{j})]= operatorname {Cov} [X_{i},X_{j}],Σi,j​=E[(Xi​−μi​)(Xj​−μj​)]=Cov[Xi​,Xj​], . such that $1 leq i leq k$ and $1 leq j leq k$ . | The general form of its probability density function is . | . fX(x1,…,xk)=exp⁡(−12(x−μ)TΣ−1(x−μ))(2π)k∥Σ∥{ displaystyle f_{ mathbf {X} }(x_{1}, ldots ,x_{k})={ frac { exp left(-{ frac {1}{2}}({ mathbf {x} }-{ boldsymbol { mu }})^{ mathrm {T} }{ boldsymbol { Sigma }}^{-1}({ mathbf {x} }-{ boldsymbol { mu }}) right)}{ sqrt {(2 pi )^{k} lVert { boldsymbol { Sigma }} rVert }}}}fX​(x1​,…,xk​)=(2π)k∥Σ∥ . ​exp(−21​(x−μ)TΣ−1(x−μ))​ . (참고) Mahalanobis distance The Mahalanobis distance is a measure of the distance between a point P and a distribution D . | . (x−μ)TΣ−1(x−μ) sqrt{({ mathbf {x} }-{ boldsymbol { mu }})^{ mathrm {T} }{ boldsymbol { Sigma }}^{-1}({ mathbf {x} }-{ boldsymbol { mu }})}(x−μ)TΣ−1(x−μ) . ​ . 만약, $ Sigma = sigma^2 I$ 이라면, 즉, 각 변수간 공분산이 모두 0인 경우, 마할라노비스 거리는 유클리디안 거리와 같아집니다. | . 9. Covariance의 의미 . Variance(분산) : 데이터가 펼쳐진 정도, 분산이 작으면, 데이터가 좁은영역에 모여있고, 분산이 크면 데이터가 넓은 영역에 퍼지는 형태를 보임 | . var⁡(X)=Cov⁡(X,X)=E⁡[(X−E⁡[X])(X−E⁡[X])T] operatorname {var} ( mathbf {X} )= operatorname {Cov} ( mathbf {X} , mathbf {X} )= operatorname {E} left[( mathbf {X} - operatorname {E} [ mathbf {X} ])( mathbf {X} - operatorname {E} [ mathbf {X} ])^{ rm {T}} right]var(X)=Cov(X,X)=E[(X−E[X])(X−E[X])T] . Covariance(공분산) : 두 변수간 데이터가 퍼진 정도를 나타냄 | . Cov⁡(X,Y)=E⁡[(X−E⁡[X])(Y−E⁡[Y])T] operatorname {Cov} ( mathbf {X} , mathbf {Y} )= operatorname {E} left[( mathbf {X} - operatorname {E} [ mathbf {X} ])( mathbf {Y} - operatorname {E} [ mathbf {Y} ])^{ rm {T}} right]Cov(X,Y)=E[(X−E[X])(Y−E[Y])T] . Covariance를 의미를 살펴보면, | . Cov(X,Y)=(x1−μx)(y1−μy)+(x2−μx)(y2−μy)+⋯+(xn−μx)(yn−μy)nCov(X, Y) = frac{(x_1 - mu_x)(y_1 - mu_y) + (x_2 - mu_x)(y_2 - mu_y) + dots + (x_n - mu_x)(y_n - mu_y)}{n}Cov(X,Y)=n(x1​−μx​)(y1​−μy​)+(x2​−μx​)(y2​−μy​)+⋯+(xn​−μx​)(yn​−μy​)​ . 이고, $(x_i - mu_x)(y_i - mu_y)$ 가 양수인 경우는 각각 평균보다 크거나, 각각 평균보다 작은 경우이며, 음수인 경우 그 반대이다. 또한 평균으로부터 값이 멀어질 수록 그 값이 커지게 된다. 즉, 각 변수의 평균을 중심으로 분산의 방향을 확인할 수 있다. 데이터를 축에 plotting했을 때, Cov(X,Y)가 양수이면, 1,3분면에 분포하며, 음수이면 주로 2,4분면에 분포할 것으로 생각할 수 있다. 다만, 공분산은 각 변수의 단위에 따라 값의 크기가 달라져서 절대적인 값의 크기로 비교하는 것은 타당하지 않다. . | 그래서, 공분산을 각각의 표준편차로 나누어 그 값을 [-1, 1]로 변환하여 계산한 것을 correlation(상관계수)라고 한다. . | . ρX,Y=corr⁡(X,Y)=Cov⁡(X,Y)σXσY=E⁡[(X−μX)(Y−μY)]σXσY,if σXσY&gt;0.{ displaystyle rho _{X,Y}= operatorname {corr} (X,Y)={ operatorname {Cov} (X,Y) over sigma _{X} sigma _{Y}}={ operatorname {E} [(X- mu _{X})(Y- mu _{Y})] over sigma _{X} sigma _{Y}}, quad { text{if}} sigma _{X} sigma _{Y}&gt;0.}ρX,Y​=corr(X,Y)=σX​σY​Cov(X,Y)​=σX​σY​E[(X−μX​)(Y−μY​)]​,if σX​σY​&gt;0. . 10. Linear Regression . 10.1 Problem definition . Data: Measured pairs $(x,y)$, where $x in R^{d+1}$ (input) and $y in R$ (output) . | Goal: Find a function $f: R^{d+1} rightarrow R$ such that $y sim f(x;w)$ for the data pair $(x,y)$. $f(x;w)$ is the regression function and the vector $w$ are its paramenters. . | Definition of linear regression: A regression method is called linear if the prediction $f$ is a linear function of the unknown parameters $w$. . | . 10.2 Least squares solution . Least squares finds the w that minimizes the sum of squared errors. The least squares objective in the most basic form where $f(x;w) = x^Tw$ is | . L=∑i=1n(yi−xiTw)2=∥y−Xw∥2=(y−Xw)T(y−Xw)L = sum_{i=1}^n (y_i - x_i^T w)^2 = lVert y-Xw rVert ^2 = (y-Xw)^T(y-Xw)L=i=1∑n​(yi​−xiT​w)2=∥y−Xw∥2=(y−Xw)T(y−Xw) . We defined $y = [y_1, dots, y_n]^T space$ and $X = [x_1, dots, x_n]^T. | . wLS=argmin⁡w∑i=1n(yi−(w0+∑j=1dxijwj))2w_{LS} = underset{w}{ operatorname{argmin}} sum_{i=1}^n (y_i - (w_0 + sum_{j=1}^d x_{ij}w_j))^2wLS​=wargmin​i=1∑n​(yi​−(w0​+j=1∑d​xij​wj​))2 . Taking the gradient with respect ot w and setting to zero, using vectors, this can be written: | . ∇wL=0 ⇒ ∑i=1n∇w(yi2−2wTxiyi+wTxixiTw)=0 nabla_{w} L = 0 space Rightarrow space sum_{i=1}^n nabla_{w} (y_i^2 - 2w^T x_i y_i + w^T x_i x_i^T w) = 0∇w​L=0 ⇒ i=1∑n​∇w​(yi2​−2wTxi​yi​+wTxi​xiT​w)=0 . solving gives, | . −∑i=1n2yixi+(∑i=1n2xixiT)w=0 ⇒ wLS=(∑i=1nxixiT)−1(∑i=1nyixi)- sum_{i=1}^n 2 y_i x_i + ( sum_{i=1}^n 2 x_i x_i^T)w = 0 space Rightarrow space w_{LS} = ( sum_{i=1}^n x_i x_i^T)^{-1}( sum_{i=1}^n y_i x_i)−i=1∑n​2yi​xi​+(i=1∑n​2xi​xiT​)w=0 ⇒ wLS​=(i=1∑n​xi​xiT​)−1(i=1∑n​yi​xi​) . solving gives as matrix version, | . wLS=(XTX)−1XTyw_{LS} = (X^T X)^{-1} X^T ywLS​=(XTX)−1XTy . In other words, $w_{LS}$ is the vector that minimizes $L$. | . 10.3 Maximum likelihood for Gaussian linear regression . Assume a diagonal covariance matrix $ Sigma = sigma^2I$. The density is | . p(y∣μ,σ2)=1(2πσ2)n2exp(−12σ2(y−μ)T(y−μ))p(y mid mu, sigma^2) = frac{1}{(2 pi sigma^2)^{ frac{n}{2}}} exp(- frac{1}{2 sigma^2}(y- mu)^T(y- mu))p(y∣μ,σ2)=(2πσ2)2n​1​exp(−2σ21​(y−μ)T(y−μ)) . Plug $ mu = Xw$ into the multivariate Gaussian distribution and solve for $w$ using maximum likelihood | . wML=argmax⁡wln p(y∣μ=Xw,σ2)w_{ML} = underset{w}{ operatorname{argmax}} ln space p(y mid mu = Xw, sigma^2)wML​=wargmax​ln p(y∣μ=Xw,σ2) . =argmax⁡w−12σ2∥y−Xw∥2−n2ln(2πσ2)= underset{w}{ operatorname{argmax}} - frac{1}{2 sigma^2} lVert y - Xw rVert^2 - frac{n}{2}ln(2 pi sigma^2)=wargmax​−2σ21​∥y−Xw∥2−2n​ln(2πσ2) . Least squares(LS) and maximum likelihood(ML) share the same solution: | . LS: argmin⁡w∥y−Xw∥2⇔ML: argmax⁡w−12σ2∥y−Xw∥2LS: space underset{w}{ operatorname{argmin}} lVert y - Xw rVert^2 Leftrightarrow ML: space underset{w}{ operatorname{argmax}} - frac{1}{2 sigma^2} lVert y - Xw rVert ^ 2LS: wargmin​∥y−Xw∥2⇔ML: wargmax​−2σ21​∥y−Xw∥2 . therefore, in a sense we are making a independent Gaussian noise assumption about the error, $ epsilon_i = y_i - x_i^Tw$ . | Other ways of saying this: 1) $y_i = x_i^Tw + epsilon_i, space epsilon_i overset{i.i.d}{ sim} N(0, sigma^2), space for space i = 1, dots, n.$ 2) $y_i overset{ind}{ sim} N(x_i^Tw, sigma^2), space for space i = 1, dots, n.$ 3) $y sim N(Xw, sigma^2I)$ . | . 11. Bayesian linear regression . 11.1 Model . Have vector $y in R^n$ and covariates matrix $X in R^{n times d}$. The ith row of $y$ and $X$ correspond to the ith observation $(y_i, x_i)$ . | In a Bayesian setting, we model this data as: . | . Likelihood: y∼N(Xw,σ2I)Likelihood: space y sim N(Xw, sigma^2I)Likelihood: y∼N(Xw,σ2I) . Prior: w∼N(0,λ−1I)Prior: space w sim N(0, lambda^{-1}I)Prior: w∼N(0,λ−1I) . Regarding prior distribution, although not covered here, see conjugate prior. . | The unknow model variable is $w in R^d$ The “likelihood model” says how well the observed data agrees with w. | The “model prior” is our prior belief (or constraints) on w. | . | This is called Bayesian linear regression because we have defined a prior on the unknown parameter and will try to learn its posterior. | . 11.2 MAP(Maximum A Posteriori) solution . Let us assume that the prior for $w$ is Gaussian, $w sim N(0, lambda^{-1}I)$. Then | . p(w)=(λ2π)d2e−λ2wTwp(w) = ( frac{ lambda}{2 pi})^{ frac{d}{2}}e^{- frac{ lambda}{2}w^Tw}p(w)=(2πλ​)2d​e−2λ​wTw . We can now try to find a $w$ that satisfies both the data likelihood, and our prior conditions about $w$. . | Maximum a posteriori (MAP) estimation seeks the most probable value $w$ under the posterior: . | . wMAP=argmax⁡w ln p(w∣y,X)w_{MAP} = underset{w}{ operatorname{argmax}} space ln space p(w mid y,X)wMAP​=wargmax​ ln p(w∣y,X) . =argmax⁡w lnp(y∣w,X)p(w)p(y∣X)= underset{w}{ operatorname{argmax}} space ln frac{p(y mid w,X_)p(w)}{p(y mid X)}=wargmax​ lnp(y∣X)p(y∣w,X)​p(w)​ . =argmax⁡w ln p(y∣w,X)+ln p(w)−ln p(y∣X)= underset{w}{ operatorname{argmax}} space ln space p(y mid w,X) + ln space p(w) - ln space p(y mid X)=wargmax​ ln p(y∣w,X)+ln p(w)−ln p(y∣X) . The normalizing constant term $ln space p(y mid X)$ doesn’t involve $w$. Therefore, we can maximize the first two terms alone. . | In many models we don’t know $ln space p(y mid X)$, so this fact is useful. . | Hence, . | . wMAP=argmax⁡w ln p(y∣w,X)+ln p(w)w_{MAP} = underset{w}{ operatorname{argmax}} space ln space p(y mid w,X) + ln space p(w)wMAP​=wargmax​ ln p(y∣w,X)+ln p(w) . =argmax⁡w −12σ2(y−Xw)T(y−Xw)−λ2wTw+const= underset{w}{ operatorname{argmax}} space - frac{1}{2 sigma^2}(y - Xw)^T(y-Xw) - frac{ lambda}{2}w^Tw + const=wargmax​ −2σ21​(y−Xw)T(y−Xw)−2λ​wTw+const . this solution for $w_{MAP}$ is the same as for ridge regression (we do not cover ridge regression(RR) here). | . wMAP=(λσ2I+XTX)−1XTy ⇔ wRRw_{MAP} = ( lambda sigma^2I + X^TX)^{-1}X^Ty space Leftrightarrow space w_{RR}wMAP​=(λσ2I+XTX)−1XTy ⇔ wRR​ . 11.3 Point estimates . $w_{MAP}$ and $w_{ML}$ are referred to as point estimates of the model parameters. | The find a specific value(point) of the vector $w$ that maximizes an objective function (MAP or ML) ML: Only consider data model | MAP: Takes into account model prior | . | Bayesian inference goes one step further by characterizing uncertainty about the values in w using Bayes rule. (Bayesian inference는 파라메터의 uncertainty(=variance)를 계산할 수 있다. parameter의 uncertainty를 구하는 것과, prediction의 uncertainty를 구하는 것에 대해 추가공부 필요!) . | In posterior calculation, we get an updated distribution on $w$ through the transition | . prior→likelihood→posteriorprior rightarrow likelihood rightarrow posteriorprior→likelihood→posterior . Bayesian learning is naturally thought of a sequential process. That is, the posterior after seeing some data becomes the prior for the next data. . | Maximum likelihood는 데이터가 주어졌을 때, OLS라는 목적함수를 최소화하는 w를 찾는 것이라면, MAP는 w에 대한 prior distribution을 가정하고, 데이터가 주어졌을 때, prior distribution을 만족하는 w를 찾는 방법이다. 이 때, $p(w mid y,X)$를 바로 구하기 어렵기 때문에, likelihood와 prior의 곱을 최소로 하는 w를 찾는다. . | .",
            "url": "https://hyunholee26.github.io/fastpages/statistics/2022/09/05/Basic-knowledge-for-understanding-Gaussian-Process-Regression.html",
            "relUrl": "/statistics/2022/09/05/Basic-knowledge-for-understanding-Gaussian-Process-Regression.html",
            "date": " • Sep 5, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Random Process",
            "content": "0. 들어가며 . Spatiotemporal Analysis를 수강하면서, Random Process를 공부하기 위해 참고사이트의 내용을 다시 정리한 글입니다. 대부분의 내용은 참고한 사이트를 따르며, 일부 제가 이해한 내용을 추가적으로 작성하였습니다. . 참고자료 https://pasus.tistory.com/209?category=1287736 | https://www.probabilitycourse.com/chapter10/10_1_0_basic_concepts.php | . | . 1. Ramdom Process . A random process is a collection of random variables usually indexed by time. . 랜덤변수(random variable)는 확률 실험의 결과에 실숫값을 대응시키는 함수로 정의된다. 또한 랜덤 프로세스(random process)는 어떤 파라미터로 인덱스(index)된 무한개의 랜덤변수의 집합으로 정의된다. | 인덱스 파라미터를 고정시킨다면 랜덤 프로세스는 랜덤변수가 된다. | . (연습문제1) $X_n = 1000(1+R)^n, for space n = 0,1,2, cdots.$ 이고, $R sim Uniform(0.04, 0.05)$인 경우, $E[X_3]$ 는? . The random variable $X_3$ is given by $X_3 = 1000(1+R)^3$. | If you let $Y = 1 + R$, then $Y sim Uniform(1.04, 1.05)$, so fY(y)={1001.04≤y≤1.05∵1/(1.05−1.04)=1000otherwisef_Y(y) = begin{cases} 100 quad 1.04 le y le 1.05 qquad because 1/(1.05 - 1.04) = 100 newline newline 0 qquad otherwise end{cases}fY​(y)=⎩⎨⎧​1001.04≤y≤1.05∵1/(1.05−1.04)=1000otherwise​ . | To obtain $E[X_3]$, we can write | . E[X3]=1000E[Y3]=1000∫1.041.05100y3dy∵E(x)=∫xp(x)dx,in this case x is y3 and p(x)=100=1054[y4]1.041.05=1054[(1.05)4−(1.04)4]≈1141.2 begin{aligned} E[X_3] &amp;= 1000E[Y^3] &amp;= 1000 int_{1.04}^{1.05} 100y^3 dy qquad because E(x) = int xp(x) dx, text{in this case} space x space is space y^3 space and space p(x) = 100 &amp;= frac{10^5}{4} [ y^4 ]_{1.04}^{1.05} &amp;= frac{10^5}{4} [(1.05)^4 - (1.04)^4] &amp; approx 1141.2 end{aligned}E[X3​]​=1000E[Y3]=1000∫1.041.05​100y3dy∵E(x)=∫xp(x)dx,in this case x is y3 and p(x)=100=4105​[y4]1.041.05​=4105​[(1.05)4−(1.04)4]≈1141.2​ . (연습문제2) Let ${X(t), t in [0, infty )}$ be defined as . X(t)=A+Bt,for all t∈[0,∞)X(t) = A + Bt, text{for all} space t in [0, infty)X(t)=A+Bt,for all t∈[0,∞) . where A and B are independent normal $N(1,1)$ random variables. . 2-1. Define the random variable $Y=X(1)$. Find the PDF of $Y$ . We have | . Y=X(1)=A+BY = X(1) = A + BY=X(1)=A+B . Since A and B are independent $N(1,1) random variable, Y = A + B is also normal with | . E[Y]=E[A+B]=E[A]+E[B]=1+1=2,Var(Y)=Var(A+B)=Var(A)+Var(B)(since A and B are independent)=1+1=2 begin{aligned} E[Y] &amp;= E[A + B] &amp;= E[A] + E[B] &amp;= 1 + 1 &amp;= 2, Var(Y) &amp;= Var(A + B) &amp;= Var(A) + Var(B) qquad text{(since A and B are independent)} &amp;= 1 + 1 &amp;= 2 end{aligned}E[Y]Var(Y)​=E[A+B]=E[A]+E[B]=1+1=2,=Var(A+B)=Var(A)+Var(B)(since A and B are independent)=1+1=2​ . Thus, we conclude that $Y∼N(2,2)$ | . 2-2. Let also $Z=X(2)$. Find $E[YZ]$ . Since Y = A + B and Z = A + 2B, so | . E[YZ]=E[(A+B)(A+2B)]=E[A2+3AB+2B2]=E[A2]+3E[AB]+2[B2]=E[A2]+3E[A]E[B]+2[B2](since A and B are independent)=Var(A)+E[A]2+3E[A]E[B]+2(Var(B)+E[B]2)=1+1+3+2(1+1)=9 begin{aligned} E[YZ] &amp;= E[(A + B)(A + 2B)] &amp;= E[A^2 + 3AB + 2B^2] &amp;= E[A^2] + 3E[AB] + 2[B^2] &amp;= E[A^2] + 3E[A]E[B] + 2[B^2] qquad text{(since A and B are independent)} &amp;= Var(A) + E[A]^2 + 3E[A]E[B] + 2(Var(B) + E[B]^2) &amp;= 1 + 1 + 3 + 2(1 + 1) &amp;= 9 end{aligned}E[YZ]​=E[(A+B)(A+2B)]=E[A2+3AB+2B2]=E[A2]+3E[AB]+2[B2]=E[A2]+3E[A]E[B]+2[B2](since A and B are independent)=Var(A)+E[A]2+3E[A]E[B]+2(Var(B)+E[B]2)=1+1+3+2(1+1)=9​ . (참고1) Expectation value는 아래의 성질을 만족함 . E[X+Y]=E[X]+E[Y]E[aX]=aE[X] begin{aligned} E[X+Y] &amp;= E[X] + E[Y] E[aX] &amp;= aE[X] end{aligned}E[X+Y]E[aX]​=E[X]+E[Y]=aE[X]​ . (참고2) Variance는 아래의 성질을 만족함 . Var(X)=E[(X−E[X])2]=∑x(x−E[X])2p(x)=∑x(x2−2E[X]x+E[X]2)p(x)=∑xx2p(x)−2E[X]∑xxp(x)+E[X]2∑xp(x)=E[X2]−2E[X]2+E[X]2=E[X2]−E[X]2Var(aX+b)=E[(aX+b−aE[X]−b)2]=E[a2(X−E[X])2]=a2E[(X−E[X])2]=a2Var(x) begin{aligned} Var(X) &amp;= E[(X - E[X])^2] &amp;= sum_x (x - E[X])^2 p(x) &amp;= sum_x (x^2 - 2 E[X] x + E[X]^2)p(x) &amp;= sum_x x^2 p(x) -2 E[X] sum_x xp(x) + E[X]^2 sum_x p(x) &amp;= E[X^2] - 2E[X]^2 + E[X]^2 &amp;= E[X^2] - E[X]^2 Var(aX + b) &amp;= E[(aX + b - aE[X] - b)^2] &amp;= E[a^2(X - E[X])^2] &amp;= a^2E[(X - E[X])^2] &amp;= a^2Var(x) end{aligned}Var(X)Var(aX+b)​=E[(X−E[X])2]=x∑​(x−E[X])2p(x)=x∑​(x2−2E[X]x+E[X]2)p(x)=x∑​x2p(x)−2E[X]x∑​xp(x)+E[X]2x∑​p(x)=E[X2]−2E[X]2+E[X]2=E[X2]−E[X]2=E[(aX+b−aE[X]−b)2]=E[a2(X−E[X])2]=a2E[(X−E[X])2]=a2Var(x)​ . (참고3) 두 random variable X, Y가 독립인 경우, 두 random variable은 uncorrelated이며, 아래의 등식이 성립합니다. E[XY]=E[X]E[Y]E[XY] = E[X]E[Y]E[XY]=E[X]E[Y] . 또한 이 성질을 이용하면 아래의 수식이 성립합니다. . Var(X+Y)=E[(X+Y)2]−(E[X+Y])2=E[X2+2XY+Y2]−(E[X]+E[Y])2=E[X2]+2E[XY]+E[Y2]−(E[X]2+2E[X]E[Y]+E[Y]2)=E[X2]−E[X]2+E[Y2]−E[Y]2=Var(X)+Var(Y) begin{aligned} Var(X+Y) &amp;= E[(X+Y)^2] - (E[X+Y])^2 &amp;= E[X^2 + 2XY + Y^2] - (E[X] + E[Y])^2 &amp;= E[X^2] + 2E[XY] + E[Y^2] - (E[X]^2 +2E[X]E[Y] + E[Y]^2) &amp;= E[X^2] - E[X]^2 + E[Y^2] - E[Y]^2 &amp;= Var(X) + Var(Y) end{aligned}Var(X+Y)​=E[(X+Y)2]−(E[X+Y])2=E[X2+2XY+Y2]−(E[X]+E[Y])2=E[X2]+2E[XY]+E[Y2]−(E[X]2+2E[X]E[Y]+E[Y]2)=E[X2]−E[X]2+E[Y2]−E[Y]2=Var(X)+Var(Y)​ . 2. Random Processes as Random Functions: . A random process is a random function of time. . random process는 index에 따른 random function으로 볼 수 있다. | . We call each of these possible functions of X(t) a sample function or sample path. It is also called a realization of X(t). . X(t)로서 가능한 모든 함수들을 sample function, sample path 또는 realization of X(t)라고 부릅니다. | . 3. Mean Function of a Random Process . For a random process ${X(t), t in J}$, the mean function $ mu_X(t) : J leftarrow R$, is defined as . μX=E[X(t)] mu_X = E[X(t)]μX​=E[X(t)] . 4. Autocorrelation and Autocovariance . For a random process ${X(t), t in J}$, the autocorrelation function or, simply, the correlation function, $R_X(t_1, t_2)$ is defined by . RX(t1,t2)=E[X(t1)X(t2)], for t1,t2∈JR_X(t1, t2) = E[X(t_1)X(t_2)], space for space t1, t2 in JRX​(t1,t2)=E[X(t1​)X(t2​)], for t1,t2∈J . For a random process ${X(t), t in J}$, the autocovariance function or, simply, the covariance function, $C_X(t_1, t_2)$ is defined by . CX(t1,t2)=Cov(X(t1),X(t2))=RX(t1,t2)−μX(t1)μX(t2), for t1,t2∈J begin{aligned} C_X(t1, t2) &amp;= Cov(X(t_1), X(t_2)) &amp;= R_X(t_1, t_2) - mu_X(t_1) mu_X(t_2), space for space t_1, t_2 in J end{aligned}CX​(t1,t2)​=Cov(X(t1​),X(t2​))=RX​(t1​,t2​)−μX​(t1​)μX​(t2​), for t1​,t2​∈J​ . Intuitively, $C_X(t1, t2)$ shows how $X(t_1)$ and $X(t_2)$ move relative to each other. If large values of $X(t_1)$ tend to imply large values of $X(t_2)$, then $(X(t_1) - E[X(t_1)])(X(t_2) - E[X(t_2])$ is positive on average. In this case, $C_X(t_1, t_2)$ is positive, and we say $X(t_1)$ and $X(t_2)$ are positively correlated. | On the other hand, if large values of $X(t_1)$ imply small values of $X(t_2)$, then $(X(t_1) - E[X(t_1)])(X(t_2) - E[X(t_2)])$ is negative on average, and we say $X(t_1)$ and $X(t_2)$ are negatively correlated. | If $C_X(t_1, t_2) = 0$ then $X(t_1)$ and $X(t_2)$ are uncorrelated. | .",
            "url": "https://hyunholee26.github.io/fastpages/statistics/2022/09/04/Random-Process.html",
            "relUrl": "/statistics/2022/09/04/Random-Process.html",
            "date": " • Sep 4, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "Devil's bridge in Sedona (22.8.28)",
            "content": ". . .",
            "url": "https://hyunholee26.github.io/fastpages/travel/2022/08/28/Devils-bridge.html",
            "relUrl": "/travel/2022/08/28/Devils-bridge.html",
            "date": " • Aug 28, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Research Interests . Main research interests are below: . Deep learning for geospatial data such as remote sensed images and DEM (digital elevation model) | Spatiotemporal data mining and applications for water resources management | Spatial data science and geographic information science | . My research focuses on incorporating domain knowledge within data-driven models or learning process as an inductive bias, thereby achieving efficient learning from few samples or sparse observations and making the model easier to understand for scientists and non-machine-learning experts. Also, I would like to research the applications of these techniques in water resources management such as the prediction of water level and dam inflow. For more information about my research experience, please refer to my Curriculum Vitae (PDF). . Education . Arizona State University, Tempe, United State Ph.D in Geographic Information Science | Aug. 2022 - Present | . | KAIST (Korea Advanced Institute of Science and Technology), Daejeon, Republic of Korea M.S in Computer Science | Mar. 2008 – Feb. 2010 | . | Ajou University, Suwon, Republic of Korea B.E in Information and Computer Engineering (intensive major course) | Mar. 2001 – Aug. 2007 | . | . Publication . J Park, H Lee (2020) “Prediction of high turbidity in rivers using LSTM algorithm”. Journal of Korean Society of Water and Wastewater 34 (1), 35-43, https://doi.org/10.11001/jksww.2020.34.1.035 . | J Kim, M Park, Y Yoon, H Lee (2020) “Application of recurrent neural network for inflow prediction into multi-purpose dam basin”. Advances in Hydroinformatics, 397-408, https://doi.org/10.1007/978-981-15-5436-0_31 . | J Park, H Lee, CY Park, S Hasan, TY Heo, WH Lee (2019) “Algal morphological identification in watersheds for drinking water supply using neural architecture search for convolutional neural network”. Water 11 (7), 1338, https://doi.org/10.3390/w11071338 . | H Lee, K Wohn (2010) “The layer-based vector texture for 3D rendering”. Proceeding of 2010 Conference on the HCI Society of Korea, 40-43 . | . Work Experience . Korea Water Resources Corporation (K-water), Daejeon, Korea, Jul. 2010 – Present . Senior Manager, Digital Water Platform Dept., Water Platform Development Team, Jan. 2021 – Jun.2022 | Manager, Digital Innovation Dept., Big Data Business Team, Jan. 2020 – Dec. 2020 | Manager, Data Center Dept., Big Data Business Team, Jan. 2019 – Dec. 2019 | Manager, Water Data Collection and Analysis Dept., Water Data Integration Team, Jan. 2018 – Dec. 2018 | Manager, Human Resources Management Dept., HR Management Team, Jan. 2013 – Dec. 2017 | Staff, Information System Management Dept., Information Planning Team, Jul. 2010 – Dec. 2012 | . | . Honors and Awards . 1st Place Prize, 5th Bigdata analysis competition in K-water, Oct. 2021 . | Academic Conference Paper Award, Korean Society of Environmental Engineering Annual Conference, Nov. 2020 . | Bronze Award, ACM-ICPC (International Collegiate Programming Contest) Asia-Seoul Regional, Nov. 2003 . | . Certification . Advanced Data Analytics Professional, certificated by K-Data, Korea, Apr. 2019 (pass rate: 2.76%) | . Professional Skills . Programming Languages : Python, R, C/C++, JAVA, ABAP (SAP) . | Data Science and Machine Learning : Keras, Tensorflow, Sci-kit Learn . | Visualization : Matplotlib, Plotly, Leaflet, QGIS, OpenGL . | .",
          "url": "https://hyunholee26.github.io/fastpages/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://hyunholee26.github.io/fastpages/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}