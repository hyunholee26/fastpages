{
  
    
        "post0": {
            "title": "Pattern Recognition and Machine Learning Summary",
            "content": "1.2 Probability Theory . The probability that $X$ will take the value $x_i$ and $Y$ will take the value $y_j$ is written $p(X = x_i, Y = y_j)$ and is called the joint probability of $X = x_i$ and $Y = y_j$. It is given by the number of points falling in the cell $i,j$ as a fraction of the total number of points, and hence | . p(X=xi,Y=yj)=nijNp(X = x_i, Y = y_j) = frac{n_{ij}}{N}p(X=xi​,Y=yj​)=Nnij​​ . p(X=xi)=ciNp(X = x_i) = frac{c_i}{N}p(X=xi​)=Nci​​ . sum rule of probability p(X=xi)=∑j=1Lp(X=xi,Y=yj)p(X = x_i) = sum_{j=1}^{L} p(X = x_i, Y = y_j)p(X=xi​)=∑j=1L​p(X=xi​,Y=yj​) Note that $p(X = x_i)$ is called the marginal probability because it is obtained by marginalizing or summing out the other variables (in this case Y) | . | If we consider only those instances for which $X = x_i$, then the fraction of such instances for which $Y = y_j$ is written $p(Y = y_j |X = x_i)$ and is called the conditional probability of $Y = y_j$ given $X = x_i$. It is obtained by finding the fraction of those points in column i that fall in cell i,j and hence is given by | . p(Y=yj∣X=xi)=nijcip(Y = y_j |X = x_i) = frac{n_{ij}}{c_i}p(Y=yj​∣X=xi​)=ci​nij​​ . product rule of probability | . p(X=xi,Y=yj)=nijN=nijci⋅ciN=p(Y=yj∣X=xi)p(X=xi)p(X = x_i, Y = y_j) = frac{n_{ij}}{N} = frac{n_{ij}}{c_i} cdot frac{c_i}{N} = p(Y=y_j|X=x_i)p(X = x_i)p(X=xi​,Y=yj​)=Nnij​​=ci​nij​​⋅Nci​​=p(Y=yj​∣X=xi​)p(X=xi​) . More compact notation, sum rule | . | . p(X)=∑Yp(X,Y)p(X) = sum_Y p(X,Y)p(X)=Y∑​p(X,Y) . product rule | . p(X,Y)=p(Y∣X)p(X)p(X,Y) = p(Y|X)p(X)p(X,Y)=p(Y∣X)p(X) . $p(X,Y) = p(Y,X)$ so, we can derive Bayes’ theorem | . p(X,Y)=p(Y∣X)p(X)=p(X∣Y)p(Y)p(X,Y) = p(Y|X)p(X) = p(X|Y)p(Y)p(X,Y)=p(Y∣X)p(X)=p(X∣Y)p(Y) . ∴p(Y∣X)=p(X∣Y)p(Y)p(X) therefore p(Y|X) = frac{p(X|Y)p(Y)}{p(X)}∴p(Y∣X)=p(X)p(X∣Y)p(Y)​ . Using the sum rule, the denominator in Bayes’ theorem can be expressed in terms of the quantities appearing in the numerator | . p(X)=∑Yp(X,Y)=∑Yp(X∣Y)p(Y)p(X) = sum_Y p(X,Y) = sum_Y p(X|Y)p(Y)p(X)=Y∑​p(X,Y)=Y∑​p(X∣Y)p(Y) . We can view the denominator in Bayes’ theorem as being the normalization constant required to ensure that the sum of the conditional probability on the left-hand side of over all values of $Y$ equals one. | . 1.2.1 Probability densities . if $x$ and $y$ are two real variables, then the sum and product rules take the form | . p(x)=∫p(x,y)dyp(x) = int p(x, y) dyp(x)=∫p(x,y)dy . p(x,y)=p(y∣x)p(x)p(x, y) = p(y|x)p(x)p(x,y)=p(y∣x)p(x) . 1.2.2 Expectations and covariances . The average value of some function $f(x)$ under a probability distribution $p(x)$ is called the expectation of f(x) and will be denoted by | . E[f]=∑xp(x)f(x)E[f] = sum_x p(x) f(x)E[f]=x∑​p(x)f(x) . or . E[f]=∫p(x)f(x)dxE[f] = int p(x) f(x) dxE[f]=∫p(x)f(x)dx . If we are given a finite number $N$ of points drawn from the probability distribution or probability density, then the expectation can be approximated as a finite sum over these points E[f]∼1N∑n=1Nf(xn)E[f] sim frac{1}{N} sum_{n=1}^{N}f(x_n)E[f]∼N1​∑n=1N​f(xn​) | $E_x[f(x, y)]$ will be a function of y, conditional expectation with respect to a conditional distribution, | . Ex[f∣y]=∑xp(x∣y)f(x)E_x[f|y] = sum_x p(x|y)f(x)Ex​[f∣y]=x∑​p(x∣y)f(x) . The variance of $f(x)$ is defined by var[f]=E[(f(x)−E[f(x)])2]=E[f(x)2]−E[f(x)]2var[f] = E[(f(x) - E[f(x)])^2] = E[f(x)^2] - E[f(x)]^2var[f]=E[(f(x)−E[f(x)])2]=E[f(x)2]−E[f(x)]2 and provides a measure of how much variability there is in $f(x)$ around its mean value $E[f(x)]$. | . | In particular, we can consider the variance of the variable x itself, which is given by var[x]=E[x2]−E[x]2var[x] = E[x^2] - E[x]^2var[x]=E[x2]−E[x]2 | For two random variables $x$ and $y$, the covariance is defined by cov[x,y]=Ex,y[(x−E[x])(y−E[y])]=Ex,y[xy]−E[x]E[y]cov[x,y] = E_{x,y}[(x-E[x])(y-E[y])] = E_{x,y}[xy] - E[x]E[y]cov[x,y]=Ex,y​[(x−E[x])(y−E[y])]=Ex,y​[xy]−E[x]E[y] If x and y are independent, then their covariance vanishes(become 0). | . | In the case of two vectors of random variables x and y, the covariance is a matrix cov[x,y]=Ex,y[(x−E[x])(yT−E[yT])]=Ex,y[xyT]−E[x]E[yT]cov[ textbf{x}, textbf{y}] = E_{ textbf{x}, textbf{y}} [( textbf{x} - E[ textbf{x}])( textbf{y}^T -E[ textbf{y}^T])] = E_{ textbf{x}, textbf{y}}[ textbf{x} textbf{y}^T] - E[ textbf{x}]E[ textbf{y}^T]cov[x,y]=Ex,y​[(x−E[x])(yT−E[yT])]=Ex,y​[xyT]−E[x]E[yT] | .",
            "url": "https://hyunholee26.github.io/fastpages/machine%20learning/2022/08/30/PRML-Summary.html",
            "relUrl": "/machine%20learning/2022/08/30/PRML-Summary.html",
            "date": " • Aug 30, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Understanding Gaussian Process Step-by-Step (차근차근 Gaussian Process 이해해보기)",
            "content": "0. Basic concepts . Sample space: the sample space of an experiment or random trial is the set of all possible outcomes or results of that experiment. An event is a subset of the sample space. 동전을 던졌을 때 나올 수 있는 결과는 앞면(H) 또는 뒷면(T)임, 발생할 수 있는 모든 경우의 수를 의미함. . | Random Variable: A Random Variable is a mathematical formalization of a quantity or object which depends on random events. It is a mapping or a function from possible outcomes in a sample space to a measurable space(아마도 확률이라는 값을 의미하는 것이 아닐지…, 즉, random variable이란 sample space(모든경우의 수)와 probability(확률값, 발생가능한 값들의 영역의 넓이?)의 맵핑이라는 것으로 해석 됨), often the real numbers. . Randome experiment 통해 Random variable은 어떠한 event로 realization됨. 결국 확률값은 event가 발생하기 이전에 가지는 값임. 이벤트가 발생하면 관측이 되는 것이고… | . | Probability: The probability of an event A is the sum of the probabilities of the individual outcomes of which it is composed. It is denoted P(A). . | . 1. Conditional probability . In probability theory, conditional probability is a measure of the probability of an event occurring, given that another event (by assumption, presumption, assertion or evidence) has already occurred. . P(A∣B)=P(A∩B)P(B)P(A | B) = frac{P( A cap B)}{P(B)}P(A∣B)=P(B)P(A∩B)​ . Independence(독립) : Two events A and B are independent if and only if their joint probability equals the product of their probabilities | . P(A∩B)=P(A)⋅P(B)P(A cap B) = P(A) cdot P(B)P(A∩B)=P(A)⋅P(B) . 조건부 확률에서 P(A)와 P(B)가 독립인 경우, $P(A | B) = frac{P( A cap B)}{P(B)} = frac{P(A) cdot P(B)}{P(B)} = P(A) $ 가 성립하며, 조건부 확률로 사건A에 대해 사건B가 주어지는 경우와 주어지지 않는 경우의 확률이 같은 경우를 의미하는 것으로 이해할 수 있다. 또한 다른말로 표현해보면, 전체에서 A가 발생할 확률과 사건B가 발생했을 때 사건A가 발생할 확률이 같은 경우를 의미하는 것으로도 이해할 수 있다. | . 2. Bayes’s Theorem . Bayes’ theorem is stated mathematically as the following equation: | . P(A∣B)=P(B∣A)⋅P(A)P(B),where P(B)≠0.P(A|B) = frac {P(B|A) cdot P(A)} {P(B)}, where space P(B) neq 0.P(A∣B)=P(B)P(B∣A)⋅P(A)​,where P(B)=0. . Bayes’s Theorem은 conditonal probability로 부터 유도됩니다. | . P(A∣B)=P(A∩B)P(B), then P(A∩B)=P(A∣B)⋅P(B)P(A | B) = frac{P( A cap B)}{P(B)}, space then space P(A cap B) = P(A | B) cdot P(B)P(A∣B)=P(B)P(A∩B)​, then P(A∩B)=P(A∣B)⋅P(B) . P(B∣A)=P(A∩B)P(A), then P(A∩B)=P(B∣A)⋅P(A)P(B | A) = frac{P( A cap B)}{P(A)}, space then space P(A cap B) = P(B | A) cdot P(A)P(B∣A)=P(A)P(A∩B)​, then P(A∩B)=P(B∣A)⋅P(A) . so,P(A∣B)⋅P(B)=P(B∣A)⋅P(A)so, P(A | B) cdot P(B) = P(B | A) cdot P(A)so,P(A∣B)⋅P(B)=P(B∣A)⋅P(A) . 3. Bayes’s Theorem 예제 . 우리나라 사람이 폐암에 걸릴 확률은 3%이고, 폐암을 99% 양성으로 진단하는 시약이 있다. 이 시약으로 폐암을 진단했을 때 양성반응을 보인 경우, 실제 폐암에 걸렸을 확률은 얼마인가? | . . 우리가 구해야할 확률은 $P(폐암|양성)$ 이고, 문제에서 주어진 조건은, | . P(폐암)=0.03 (⇒P(정상)=0.97),P(폐암) = 0.03 space ( Rightarrow P(정상) = 0.97),P(폐암)=0.03 (⇒P(정상)=0.97), . P(양성∣폐암)=0.99 (⇒P(양성∣정상)=0.01)P(양성|폐암) = 0.99 space ( Rightarrow P(양성|정상) = 0.01)P(양성∣폐암)=0.99 (⇒P(양성∣정상)=0.01) . . Bayes’s theorem을 이용하면, | . P(폐암∣양성)=P(양성∣폐암)⋅P(폐암)/P(양성)P(폐암|양성) = P(양성|폐암) cdot P(폐암) / P(양성)P(폐암∣양성)=P(양성∣폐암)⋅P(폐암)/P(양성) . P(양성)=P(양성∣정상)⋅P(정상)+P(양성∣폐암)⋅P(폐암)P(양성) = P(양성|정상) cdot P(정상) + P(양성|폐암) cdot P(폐암)P(양성)=P(양성∣정상)⋅P(정상)+P(양성∣폐암)⋅P(폐암) . 이며, 이를 계산하면, $P(양성) = 0.01 * 0.97 + 0.99 * 0.03 = 0.03939109$ | . . 따라서 $P(폐암|양성) = 0.99 * 0.03 / 0.03939109 = 0.7539776127037866$ 이며, 약 75%임. | . 4. Maximum likelihood estimation(MLE) . In statistics, maximum likelihood estimation (MLE) is a method of estimating the parameters of an assumed probability distribution, given some observed data. This is achieved by maximizing a likelihood function so that, under the assumed statistical model, the observed data is most probable. The point in the parameter space that maximizes the likelihood function is called the maximum likelihood estimate. – From wikipedia . MLE는 주어진 관측데이터( $x_1, x_2, dots, x_n$ )에 대해, 어떠한 분포를 가정했을 때, 관측데이터와 가장 유사한 분포를 만드는 파라메터( $ theta$ )를 추정하는 방법입니다. | We pick the distribution family p(·), but don’t know the parameter θ | MLE를 수식으로 표현하면 아래와 같습니다. | . θ^MLE=argmax⁡θp(x1,x2,…,xn∣θ) hat theta_{MLE} = underset{ theta}{ operatorname{argmax}} p(x_1, x_2, dots, x_n| theta)θ^MLE​=θargmax​p(x1​,x2​,…,xn​∣θ) . Assume data is independent and identically distributed (iid). This is written | . xi∼i.i.dp(x∣θ),i=1,…,nx_i overset{i.i.d}{ sim} p(x| theta), i = 1, dots, nxi​∼i.i.dp(x∣θ),i=1,…,n . Writing the density as $p(x|θ)$ , then the joint density decomposes as | . p(x1,x2,…,xn∣θ)=∏i=1np(xi∣θ)p(x_1, x_2, dots, x_n| theta) = prod_{i=1}^n p(x_i | theta)p(x1​,x2​,…,xn​∣θ)=i=1∏n​p(xi​∣θ) . 그리고 다음과 같이 Maximum Likelihood가 되는 파라메터(θ)를 추정할 수 있습니다. | . ∇θp(x1,x2,…,xn∣θ)=∇θ∏i=1np(xi∣θ)=0 nabla_{ theta} p(x_1, x_2, dots, x_n| theta) = nabla_{ theta} prod_{i=1}^n p(x_i | theta) = 0∇θ​p(x1​,x2​,…,xn​∣θ)=∇θ​i=1∏n​p(xi​∣θ)=0 . Logarithm tric : It is complicated to calcuate it directly. So we use the fact that the logarithm is monotonically increasing on R+, and the equality | . argmax⁡θg(y)=argmax⁡θln(g(y)) underset{ theta}{ operatorname{argmax}} g(y) = underset{ theta}{ operatorname{argmax}} ln(g(y))θargmax​g(y)=θargmax​ln(g(y)) . ln(∏ifi)=∑iln(fi)ln( prod_i f_i) = sum_i ln(f_i)ln(i∏​fi​)=i∑​ln(fi​) . 데이터 특징에 따라 선택할 수 있는 분포들은 binomial, poisson, gaussian 등이 있습니다. | . 5. MLE 예제 . 공장에서 10개의 제품을 검사했을 때, 정상이 8개, 불량이 2개인 경우가 관측되었습니다. 이 경우, 우리는 binomial distribution을 가정할 수 있습니다. binomial distribution의 pmf는 다음과 같이 정의됩니다. | . Pr⁡(K=k)=f(k;n,θ)=(nk)θk(1−θ)n−k Pr(K = k) = f(k;n, theta)={n choose k} theta^k(1- theta)^{n-k}Pr(K=k)=f(k;n,θ)=(kn​)θk(1−θ)n−k . 파라메터 θ를 MLE로 추정해보면, | . ∇θ∏i=1np(xi∣θ)=∇θln(∏i=1np(xi∣θ))=∇θln((nk)θk(1−θ)n−k)=0 nabla_{ theta} prod_{i=1}^n p(x_i | theta) = nabla_{ theta} ln( prod_{i=1}^n p(x_i | theta)) = nabla_{ theta} ln({n choose k} theta^k(1- theta)^{n-k}) = 0∇θ​i=1∏n​p(xi​∣θ)=∇θ​ln(i=1∏n​p(xi​∣θ))=∇θ​ln((kn​)θk(1−θ)n−k)=0 . ∇θln(θk(1−θ)n−k)=∇θk⋅ln(θ)+(n−k)⋅ln(1−θ)=kθ−n−k1−θ=0 nabla_{ theta} ln( theta^k(1- theta)^{n-k}) = nabla_{ theta} k cdot ln( theta) + (n-k) cdot ln(1- theta) = displaystyle frac{k}{ theta} - frac{n-k}{1- theta} = 0∇θ​ln(θk(1−θ)n−k)=∇θ​k⋅ln(θ)+(n−k)⋅ln(1−θ)=θk​−1−θn−k​=0 . k(1−θ)−θ(n−k)=0k(1- theta) - theta(n-k) = 0k(1−θ)−θ(n−k)=0 . θ=kn theta = displaystyle frac{k}{n}θ=nk​ . MLE를 통해 불량확률에 파라메터는 θ는, n = 10, k = 2인 경우, 0.2로 추정할 수 있습니다. | multivariate gaussian distribution에 MLE를 적용하면, mean과 covariance는 각각 아래와 같습니다.(계산유도과정은 생략합니다) | . μ^MLE=1n∑i=1nxi, σ^MLE=1n∑i=1n(xi−μ^MLE)(xi−μ^MLE)T hat mu_{MLE} = frac{1}{n} sum_{i=1}^n x_i, space hat sigma_{MLE} = frac{1}{n} sum_{i=1}^n (x_i - hat mu_{MLE})(x_i - hat mu_{MLE})^Tμ^​MLE​=n1​i=1∑n​xi​, σ^MLE​=n1​i=1∑n​(xi​−μ^​MLE​)(xi​−μ^​MLE​)T . If $x_1, dots x_n$ don’t “capture the space” well, $ theta_{MLE}$ can overfit the data. | 관측데이터에 overfitting되지 않는 파라메터(모수) 추정 방법에 대한 문제를 제기하는 것 같습니다. 아마도 뒤에서 Bayesian 방법론을 적용할 듯합니다. | . 6. Gaussian Distribution . 6-1. Univariate Gaussian Distribution . In statistics, a normal distribution (also known as Gaussian, Gauss, or Laplace–Gauss distribution) is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function is | . f(x)=1σ2πe−12(x−μσ)2f(x) = frac {1}{ sigma sqrt{2 pi}} e ^ {- frac{1}{2}( frac{x- mu}{ sigma})^2}f(x)=σ2π . ​1​e−21​(σx−μ​)2 . random variable X is normally distributed with mean $ mu$ and standard deviation $ sigma$ , one may write $ displaystyle X sim { mathcal {N}}( mu , sigma ^{2})$ | . . 6-2. Multivariate Gaussian Distribution . The multivariate normal distribution of a k-dimensional random vector $X =(X_{1}, dots ,X_{k})^{T}$ can be written in the following notation: | . X∼Nk(μ,Σ),X sim { mathcal {N}}_{k} ({ boldsymbol { mu }},{ boldsymbol { Sigma }}),X∼Nk​(μ,Σ), . with k-dimensional mean vector | . μ=E⁡[X]=(E⁡[X1],E⁡[X2],…,E⁡[Xk])T,{ boldsymbol { mu }= operatorname {E} [ mathbf {X} ]=( operatorname {E} [X_{1}], operatorname {E} [X_{2}], ldots , operatorname {E} [X_{k}])^{ textbf {T}},}μ=E[X]=(E[X1​],E[X2​],…,E[Xk​])T, . and k x k covariance matrix | . Σi,j=E⁡[(Xi−μi)(Xj−μj)]=Cov⁡[Xi,Xj], Sigma_{i,j}= operatorname {E} [(X_{i}- mu _{i})(X_{j}- mu _{j})]= operatorname {Cov} [X_{i},X_{j}],Σi,j​=E[(Xi​−μi​)(Xj​−μj​)]=Cov[Xi​,Xj​], . such that $1 leq i leq k$ and $1 leq j leq k$ | . . The general form of its probability density function is | . fX(x1,…,xk)=exp⁡(−12(x−μ)TΣ−1(x−μ))(2π)k∣Σ∣{ displaystyle f_{ mathbf {X} }(x_{1}, ldots ,x_{k})={ frac { exp left(-{ frac {1}{2}}({ mathbf {x} }-{ boldsymbol { mu }})^{ mathrm {T} }{ boldsymbol { Sigma }}^{-1}({ mathbf {x} }-{ boldsymbol { mu }}) right)}{ sqrt {(2 pi )^{k}|{ boldsymbol { Sigma }}|}}}}fX​(x1​,…,xk​)=(2π)k∣Σ∣ . ​exp(−21​(x−μ)TΣ−1(x−μ))​ . (참고) Mahalanobis distance The Mahalanobis distance is a measure of the distance between a point P and a distribution D . | . (x−μ)TΣ−1(x−μ) sqrt{({ mathbf {x} }-{ boldsymbol { mu }})^{ mathrm {T} }{ boldsymbol { Sigma }}^{-1}({ mathbf {x} }-{ boldsymbol { mu }})}(x−μ)TΣ−1(x−μ) . ​ . 만약, $ Sigma = sigma^2 I$ 이라면, 즉, 각 변수간 공분산이 모두 0인 경우, 마할라노비스 거리는 유클리디안 거리와 같아집니다. | . 7. Covariance의 의미 . Variance(분산) : 데이터가 펼쳐진 정도, 분산이 작으면, 데이터가 좁은영역에 모여있고, 분산이 크면 데이터가 넓은 영역에 퍼지는 형태를 보임 | . var⁡(X)=Cov⁡(X,X)=E⁡[(X−E⁡[X])(X−E⁡[X])T] operatorname {var} ( mathbf {X} )= operatorname {Cov} ( mathbf {X} , mathbf {X} )= operatorname {E} left[( mathbf {X} - operatorname {E} [ mathbf {X} ])( mathbf {X} - operatorname {E} [ mathbf {X} ])^{ rm {T}} right]var(X)=Cov(X,X)=E[(X−E[X])(X−E[X])T] . Covariance(공분산) : 두 변수간 데이터가 퍼진 정도를 나타냄 | . Cov⁡(X,Y)=E⁡[(X−E⁡[X])(Y−E⁡[Y])T] operatorname {Cov} ( mathbf {X} , mathbf {Y} )= operatorname {E} left[( mathbf {X} - operatorname {E} [ mathbf {X} ])( mathbf {Y} - operatorname {E} [ mathbf {Y} ])^{ rm {T}} right]Cov(X,Y)=E[(X−E[X])(Y−E[Y])T] . Covariance를 의미를 살펴보면, | . Cov(X,Y)=(x1−μx)(y1−μy)+(x2−μx)(y2−μy)+⋯+(xn−μx)(yn−μy)nCov(X, Y) = frac{(x_1 - mu_x)(y_1 - mu_y) + (x_2 - mu_x)(y_2 - mu_y) + dots + (x_n - mu_x)(y_n - mu_y)}{n}Cov(X,Y)=n(x1​−μx​)(y1​−μy​)+(x2​−μx​)(y2​−μy​)+⋯+(xn​−μx​)(yn​−μy​)​ . 이고, $(x_i - mu_x)(y_i - mu_y)$ 가 양수인 경우는 각각 평균보다 크거나, 각각 평균보다 작은 경우이며, 음수인 경우 그 반대이다. 또한 평균으로부터 값이 멀어질 수록 그 값이 커지게 된다. 즉, 각 변수의 평균을 중심으로 분산의 방향을 확인할 수 있다. 데이터를 축에 plotting했을 때, Cov(X,Y)가 양수이면, 1,3분면에 분포하며, 음수이면 주로 2,4분면에 분포할 것으로 생각할 수 있다. 다만, 공분산은 각 변수의 단위에 따라 값의 크기가 달라져서 절대적인 값의 크기로 비교하는 것은 타당하지 않다. | . . 그래서, 공분산을 각각의 표준편차로 나누어 그 값을 [-1, 1]로 변환하여 계산한 것을 correlation(상관계수)라고 한다. | . ρX,Y=corr⁡(X,Y)=Cov⁡(X,Y)σXσY=E⁡[(X−μX)(Y−μY)]σXσY,if σXσY&gt;0.{ displaystyle rho _{X,Y}= operatorname {corr} (X,Y)={ operatorname {Cov} (X,Y) over sigma _{X} sigma _{Y}}={ operatorname {E} [(X- mu _{X})(Y- mu _{Y})] over sigma _{X} sigma _{Y}}, quad { text{if}} sigma _{X} sigma _{Y}&gt;0.}ρX,Y​=corr(X,Y)=σX​σY​Cov(X,Y)​=σX​σY​E[(X−μX​)(Y−μY​)]​,if σX​σY​&gt;0. . 8. Linear Regression . 8.1 Problem definition . Data: Measured pairs $(x,y)$ , where $x in R^{d+1}$ (input) and $y in R$ (output) . | Goal: Find a function $f: R^{d+1} rightarrow R$ such that $y sim f(x;w)$ for the data pair $(x,y)$ . $f(x;w)$ is the regression function and the vector $w$ are its paramenters. . | Definition of linear regression: A regression method is called linear if the prediction $f$ is a linear function of the unknown parameters $w$ . . | . 8.2 Least squares solution . Least squares finds the w that minimizes the sum of squared errors. The least squares objective in the most basic form where $f(x;w) = x^Tw$ is | . L=∑i=1n(yi−xiTw)2=∥y−Xw∥2=(y−Xw)T(y−Xw)L = sum_{i=1}^n (y_i - x_i^T w)^2 = lVert y-Xw rVert ^2 = (y-Xw)^T(y-Xw)L=i=1∑n​(yi​−xiT​w)2=∥y−Xw∥2=(y−Xw)T(y−Xw) . We defined $y = [y_1, dots, y_n]^T space$ and $X = [x_1, dots, x_n]^T . | . wLS=argmin⁡w∑i=1n(yi−(w0+∑j=1dxijwj))2w_{LS} = underset{w}{ operatorname{argmin}} sum_{i=1}^n (y_i - (w_0 + sum_{j=1}^d x_{ij}w_j))^2wLS​=wargmin​i=1∑n​(yi​−(w0​+j=1∑d​xij​wj​))2 . Taking the gradient with respect ot w and setting to zero, using vectors, this can be written: | . ∇wL=0 ⇒ ∑i=1n∇w(yi2−2wTxiyi+wTxixiTw)=0 nabla_{w} L = 0 space Rightarrow space sum_{i=1}^n nabla_{w} (y_i^2 - 2w^T x_i y_i + w^T x_i x_i^T w) = 0∇w​L=0 ⇒ i=1∑n​∇w​(yi2​−2wTxi​yi​+wTxi​xiT​w)=0 . solving gives, | . −∑i=1n2yixi+(∑i=1n2xixiT)w=0 ⇒ wLS=(∑i=1nxixiT)−1(∑i=1nyixi)- sum_{i=1}^n 2 y_i x_i + ( sum_{i=1}^n 2 x_i x_i^T)w = 0 space Rightarrow space w_{LS} = ( sum_{i=1}^n x_i x_i^T)^{-1}( sum_{i=1}^n y_i x_i)−i=1∑n​2yi​xi​+(i=1∑n​2xi​xiT​)w=0 ⇒ wLS​=(i=1∑n​xi​xiT​)−1(i=1∑n​yi​xi​) . solving gives as matrix version, | . wLS=(XTX)−1XTyw_{LS} = (X^T X)^{-1} X^T ywLS​=(XTX)−1XTy . In other words, $w_{LS}$ is the vector that minimizes $L$ . | . 8.3 Maximum likelihood for Gaussian linear regression . Assume a diagonal covariance matrix $ Sigma = sigma^2I$ . The density is | . p(y∣μ,σ2)=1(2πσ2)n2exp(−12σ2(y−μ)T(y−μ))p(y| mu, sigma^2) = frac{1}{(2 pi sigma^2)^{ frac{n}{2}}} exp(- frac{1}{2 sigma^2}(y- mu)^T(y- mu))p(y∣μ,σ2)=(2πσ2)2n​1​exp(−2σ21​(y−μ)T(y−μ)) . Plug $ mu = Xw$ into the multivariate Gaussian distribution and solve for $w$ using maximum likelihood | . wML=argmax⁡wln p(y∣μ=Xw,σ2)w_{ML} = underset{w}{ operatorname{argmax}} ln space p(y| mu = Xw, sigma^2)wML​=wargmax​ln p(y∣μ=Xw,σ2) . =argmax⁡w−12σ2∥y−Xw∥2−n2ln(2πσ2)= underset{w}{ operatorname{argmax}} - frac{1}{2 sigma^2} lVert y - Xw rVert^2 - frac{n}{2}ln(2 pi sigma^2)=wargmax​−2σ21​∥y−Xw∥2−2n​ln(2πσ2) . Least squares(LS) and maximum likelihood(ML) share the same solution: | . LS: argmin⁡w∥y−Xw∥2⇔ML: argmax⁡w−12σ2∥y−Xw∥2LS: space underset{w}{ operatorname{argmin}} lVert y - Xw rVert^2 Leftrightarrow ML: space underset{w}{ operatorname{argmax}} - frac{1}{2 sigma^2} lVert y - Xw rVert ^ 2LS: wargmin​∥y−Xw∥2⇔ML: wargmax​−2σ21​∥y−Xw∥2 . therefore, in a sense we are making a independent Gaussian noise assumption about the error, $ epsilon_i = y_i - x_i^Tw$ . | Other ways of saying this: 1) $y_i = x_i^Tw + epsilon_i, space epsilon_i overset{i.i.d}{ sim} N(0, sigma^2), space for space i = 1, dots, n.$ 2) $y_i overset{ind}{ sim} N(x_i^Tw, sigma^2), space for space i = 1, dots, n.$ 3) $y sim N(Xw, sigma^2I)$ . | . 9. Bayesian linear regression . 9.1 Model . Have vector $y in R^n$ and covariates matrix $X in R^{n times d}$. The ith row of $y$ and $X$ correspond to the ith observation $(y_i, x_i)$ . | In a Bayesian setting, we model this data as: . | . Likelihood: y∼N(Xw,σ2I)Likelihood: space y sim N(Xw, sigma^2I)Likelihood: y∼N(Xw,σ2I) . Prior: w∼N(0,λ−1I)Prior: space w sim N(0, lambda^{-1}I)Prior: w∼N(0,λ−1I) . Regarding prior distribution, although not covered here, see conjugate prior. . | The unknow model variable is $w in R^d$ The “likelihood model” says how well the observed data agrees with w. | The “model prior” is our prior belief (or constraints) on w. | . | This is called Bayesian linear regression because we have defined a prior on the unknown parameter and will try to learn its posterior. | . 9.2 MAP(Maximum A Posteriori) solution . Let us assume that the prior for $w$ is Gaussian, $w sim N(0, lambda^{-1}I)$. Then | . p(w)=(λ2π)d2e−λ2wTwp(w) = ( frac{ lambda}{2 pi})^{ frac{d}{2}}e^{- frac{ lambda}{2}w^Tw}p(w)=(2πλ​)2d​e−2λ​wTw . We can now try to find a $w$ that satisfies both the data likelihood, and our prior conditions about $w$. . | Maximum a posteriori (MAP) estimation seeks the most probable value $w$ under the posterior: . | . wMAP=argmax⁡w ln p(w∣y,X)w_{MAP} = underset{w}{ operatorname{argmax}} space ln space p(w|y,X)wMAP​=wargmax​ ln p(w∣y,X) . =argmax⁡w lnp(y∣w,X)p(w)p(y∣X)= underset{w}{ operatorname{argmax}} space ln frac{p(y|w,X_)p(w)}{p(y|X)}=wargmax​ lnp(y∣X)p(y∣w,X)​p(w)​ . =argmax⁡w ln p(y∣w,X)+ln p(w)−ln p(y∣X)= underset{w}{ operatorname{argmax}} space ln space p(y|w,X) + ln space p(w) - ln space p(y|X)=wargmax​ ln p(y∣w,X)+ln p(w)−ln p(y∣X) . The normalizing constant term $ln space p(y | X)$ doesn’t involve $w$. Therefore, we can maximize the first two terms alone. | . | In many models we don’t know $ln space p(y | X)$, so this fact is useful. | . | Hence, | . wMAP=argmax⁡w ln p(y∣w,X)+ln p(w)w_{MAP} = underset{w}{ operatorname{argmax}} space ln space p(y|w,X) + ln space p(w)wMAP​=wargmax​ ln p(y∣w,X)+ln p(w) . =argmax⁡w −12σ2(y−Xw)T(y−Xw)−λ2wTw+const= underset{w}{ operatorname{argmax}} space - frac{1}{2 sigma^2}(y - Xw)^T(y-Xw) - frac{ lambda}{2}w^Tw + const=wargmax​ −2σ21​(y−Xw)T(y−Xw)−2λ​wTw+const . this solution for $w_{MAP}$ is the same as for ridge regression (we do not cover ridge regression(RR) here). | . wMAP=(λσ2I+XTX)−1XTy ⇔ wRRw_{MAP} = ( lambda sigma^2I + X^TX)^{-1}X^Ty space Leftrightarrow space w_{RR}wMAP​=(λσ2I+XTX)−1XTy ⇔ wRR​ . 9.3 Point estimates . $w_{MAP}$ and $w_{ML}$ are referred to as point estimates of the model parameters. | The find a specific value(point) of the vector $w$ that maximizes an objective function (MAP or ML) ML: Only consider data model | MAP: Takes into account model prior | | . | Bayesian inference goes one step further by characterizing uncertainty about the values in w using Bayes rule. (Bayesian inference는 파라메터의 uncertainty(=variance)를 계산할 수 있다. parameter의 uncertainty를 구하는 것과, prediction의 uncertainty를 구하는 것에 대해 추가공부 필요!) . | In posterior calculation, we get an updated distribution on $w$ through the transition | . prior→likelihood→posteriorprior rightarrow likelihood rightarrow posteriorprior→likelihood→posterior . Bayesian learning is naturally thought of a sequential process. That is, the posterior after seeing some data becomes the prior for the next data. . | Maximum likelihood는 데이터가 주어졌을 때, OLS라는 목적함수를 최소화하는 w를 찾는 것이라면, MAP는 w에 대한 prior distribution을 가정하고, 데이터가 주어졌을 때, prior distribution을 만족하는 w를 찾는 방법이다. 이 때, $p(w | y,X)$를 바로 구하기 어렵기 때문에, likelihood와 prior의 곱을 최소로 하는 w를 찾는다. | . | . 10. Random process . 10.1 Definition . A random process is a collection of random variables usually indexed by time. A continuous-time random process is a random process ${X(t),t in J}$, where $J$ is an interval on the real line such as $[−1,1], [0, infty), (- infty, infty)$, etc. | A discrete-time random process (or a random sequence) is a random process ${X(n)=X_n, space n in J}$, where $J$ is a countable set such as N or Z. | . | A random process is a random function of time. | . 11. Gaussian process . A random process X(t) is a Gaussian process if for all k ∈ N for all t1, … ,tk , a random vector formed by X(1), … , X(tk) is jointly Gaussian. | The joint density is completely specified by | Mean: m(t) = E(X(t)), where m(·) is known as a mean function. | Covariance: k(t, s) = Cov(X(t), X(s)), where k(·,·) is known as a covariance function. | Notation: | . X(t)∼GP(m(t),k(t,s))X(t) sim GP(m(t), k(t,s))X(t)∼GP(m(t),k(t,s)) . Example: X(t) = tA, where $A sim N(0,1)$ and t ∈ R Mean: m(t) = E(X(t)) = tE(A) = 0 | Covariance: k(t,s) = E(tAsA) = ts | . | Gaussian process and Gaussian process regression are different. | . 12. Gaussian process regression . A nonparametric Bayesian regression method using the properties of Gaussian processes. | Two views to interpret Gaussian process regression Weight-space view | Function-space view | . | . 12.1 Weight-space view . | .",
            "url": "https://hyunholee26.github.io/fastpages/gaussian%20process/gaussian%20process%20regression/2022/08/26/Understanding-Gaussian-Process-Step-by-Step.html",
            "relUrl": "/gaussian%20process/gaussian%20process%20regression/2022/08/26/Understanding-Gaussian-Process-Step-by-Step.html",
            "date": " • Aug 26, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Useful expressions in English",
            "content": "2022-03-23 . inform : 목적어로 정보를 전달하고자 하는 사람이 와야한다. inform 사람 of 정보 inform 사람 that My daughter informed me that she was pregnant Please inform me of the result of the game . notify : inform과 형태는 같으나 공식적으로 정보를 전달하는 경우 사용된다 notify 사람 of 정보 notify 사람 that The committee’s decision will be notified to all employees Competition winners will be notified by post . announce : 목적어로 전달하고자 하는 정보가 와야한다. He has announced his intention to retire Please announce to me the result of the game . be familiar with : ~ 를 잘 알다 -&gt; have some knowledge, knowing someone = be acquainted with I am familiar with the reporter. . be used to : ~ 에 익숙하다 -&gt; have some experience = be accustomed to I am not used to eating alone. . 2022-03-12 . How is it going(=coming along)? | I am afraid that it is diffcult to finish it as scheduled(=as we planned). | This is a top priority. Mr.Kyle wants the document this(every, last) week. | After this meeting, I will have Jane finish my other work. | If you have to, do it. | Do not hesitate to contact me if you have any question about(=regarding) this work. | I would appreciate it if you would let me know before you send it to him. tell me : 샅샅히 알려주다 | let me know : 변경사항만 알려주다 | . | Help yourself(많이 퍼가세요, 상황에 맞게 사용해야함), Enjoy your meal 이 오히려 적합할 수 있음 | What are you thinking about? | I was thiking of calling Paul(=give Paul a call, make a phone call). about : 전반적인 사항에 관해 | of : 구체적인 아이디어 | on : 전문적인 사항 | . | I have a presentation on the 29th, and I have to prepare with Paul. prepare : 프로젝트 준비 | get ready : 동작을 할 준비, get ready for dinner, get ready for bed | . | You are lucky. | Paul is good at computers. | Good for you : 잘됐다 | That is good for you : 몸에 좋아 | I am relieved, That is a relief, I am glad : 다행이다 | I was worried about computer work. (a work : 예술작품) | I need to get to know Paul better. get close : get close to each other (물리적 거리) | be close : I am close to Selley. | get to know (someone) | . | That is a good idea but I do not think (that) I can go. | I an going skiing tomorrow, so I have to do a lot of work will : 보통 말하는 순간에 결정할때 사용 | be going to : 예정된 일에 사용 | go (Verb)ing : 활동을 하러가다, go walking, go swimming, go skiing | I did a lot of reading, I did little reading. | . | Do you know any good bars near our office? | I will text(email, katok) you the address later. | I made a reservation for(목적지를 바라보는 전치사) seven o’clock tomorrow at a famous Korean restaurant. make a reservation : 자리를 미리 맡아놓다 | reserve + something : I would like to reserve three tables. | make an appointment : 서비스를 받을 예약을 하다 | . | Have you ever eaten Korean food? | I have never eaten(=had, tried) Korean food | How does it taste? (먹어본 경우) | What is it like(안먹어본경우, 어때요?) | Korean food is usually salty and a little spicy. | Can you eat spicy food? well : 잘 하는것 | . | Yes(Sure, Of course), I can eat everything. =&gt; 남기지 않고 싹 다 먹는다. | Yes, I can eat almost anything. I am not a picky either. : 아무거나 다 먹는다 | I am picky about food. : 입맛이 까다로워요 | That is great, Terrific, Perfect | If you want, I will order for you. instead of : 하나를 포기하는 개념이 포함됨 | on behalf of : ~ 를 대표하여 | . | Tonight, I am going with Selley to the restaurant you recommended last time. will : 말하는 순간에 결정 | be going to : 예정된 미래의 일 | . | The restaurant is very famous for its traditional Korean food. be famous for (소유격) : She is famous for her beautiful voice. | . | I know, I am looking forward toit. | I cannot wait to see you, I am really looking forward to seeing(meeting) you. | Have you ever used chopsticks before? | I used them a few times when I was in Japan. | Are they different from Japanese chopsticks? | What is the difference between Korean chopsticks and Japanese chopsticks? | Korean chopstick are thinner and made of steel. | I am worried that (~할까봐 걱정하다) | I am worried because I haven’t been feeling well these days. | Health is the most important things | What’s the matter? | What’s the problem? | My health is not as good as before | My health is not as good as it used to be | I am not as healthy as I used to be / before | I get tired easily | Do you exercise? work out : 근육운동 | . | Since I started exercising, I have been feeling much(= a lot) better. | I have been exercising these days, and I love it so much. | I quit exercising because of the air is dirty. to 부정사 : ~ 하기 위해 멈추다(미래의미) | -ing : ~ 해 오던 것을 멈추다(과거~미래) | . | I just exercise at home in the house : 물리적인 집 | at home : 나의 생활 공간으로써의 집 | . | Thirty minutes a day is enough. 시간이나 돈의 양은 단수 취급 | . | You’re right, the air pollution is just an excuse. | I should try to lose weight. | I will get started today(on Tuesday) | How have you been, How are you doing? | I heard that you are moving to the US. (제 3자로부터 들었을때) | It all happened so fast. | Things happened so suddenly | Everything happened all of sudden. | I still can’t believe it | I am still trying to wrap my head around it.(아직도 믿기지 않아) | Do you need a help?/ Can I help you? (상대방이 어떤 도움이 필요한지 알고 있을때, 보일때 사용) | Is there anything I can do for you? | Is there anything you need? | I am okay, I am fine : 호의에 대한 거절 | That sounds good. : 좋아! | Thanks for saying that. | Thanks for asking (그렇게 말해줘서 고마워) | Let me know if there’s anything I can do for you (you need) | Don’t hesitate to ask if you need any help. | I hope everty thing goes well. | I wish you the best. | How do you like living in America? | I like the fact that the air is clean. | I like the clean air. | I miss my family and friend | I you have time, When you have time, If you can, When you can | come visit me | I will go see you | I wish I could (go visit you) | I am busy, I have a lot of work. | Have you heard of Squid game? | I have heard a lot about you | It is a lot of fun. (어떤 행동 동작이 재미있는) | It’s really good, It’s really interesting(영화등이 재미있을때) | I am binge-watching it | I am hooked after one episode. | I haven’t seen it yet : 아직 안봤다 see : 어떤 존재를 인지(aware)하다 | watch : 정지상태에서 무엇가를 지켜보다 | . | It seems to be very popular among America. | The show is a big hit in American. | I can’t watch it because I am too busy with(because of를 쓰지 않는다) work and kids. | I am so busy that I can’t watch it | I am too busy to watch it | Why don’t you watch it after putting your kids to bed. make : 억지로/강제로 하다 | . | I am so tired at night that I go to bed at the same time as my kids | That’s too bad. You would like it. : 안타깝다 니가 좋아할텐데 | I got my hair cut. | I got my car washed. | I got my coat cleaned | I got everything done. | I got my suit made. | I have to get my passport picture taken | I will get your watch fixed | Would you mind | . 쓰는영어 .",
            "url": "https://hyunholee26.github.io/fastpages/english/2022/03/12/useful-expressions-in-english.html",
            "relUrl": "/english/2022/03/12/useful-expressions-in-english.html",
            "date": " • Mar 12, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Research Interests . Main research interests are below: . Deep learning for geospatial data such as remote sensed images and DEM (digital elevation model) | Spatiotemporal data mining and applications for water resources management | Spatial data science and geographic information science | . My research focuses on incorporating domain knowledge within data-driven models or learning process as an inductive bias, thereby achieving efficient learning from few samples or sparse observations and making the model easier to understand for scientists and non-machine-learning experts. Also, I would like to research the applications of these techniques in water resources management such as the prediction of water level and dam inflow. For more information about my research experience, please refer to my Curriculum Vitae (PDF). . Education . Arizona State University, Tempe, United State Ph.D in Geographic Information Science | Aug. 2022 - Present | . | KAIST (Korea Advanced Institute of Science and Technology), Daejeon, Republic of Korea M.S in Computer Science | Mar. 2008 – Feb. 2010 | . | Ajou University, Suwon, Republic of Korea B.E in Information and Computer Engineering (intensive major course) | Mar. 2001 – Aug. 2007 | . | . Publication . J Park, H Lee (2020) “Prediction of high turbidity in rivers using LSTM algorithm”. Journal of Korean Society of Water and Wastewater 34 (1), 35-43, https://doi.org/10.11001/jksww.2020.34.1.035 . | J Kim, M Park, Y Yoon, H Lee (2020) “Application of recurrent neural network for inflow prediction into multi-purpose dam basin”. Advances in Hydroinformatics, 397-408, https://doi.org/10.1007/978-981-15-5436-0_31 . | J Park, H Lee, CY Park, S Hasan, TY Heo, WH Lee (2019) “Algal morphological identification in watersheds for drinking water supply using neural architecture search for convolutional neural network”. Water 11 (7), 1338, https://doi.org/10.3390/w11071338 . | H Lee, K Wohn (2010) “The layer-based vector texture for 3D rendering”. Proceeding of 2010 Conference on the HCI Society of Korea, 40-43 . | . Work Experience . Korea Water Resources Corporation (K-water), Daejeon, Korea, Jul. 2010 – Present . Senior Manager, Digital Water Platform Dept., Water Platform Development Team, Jan. 2021 – Jun.2022 | Manager, Digital Innovation Dept., Big Data Business Team, Jan. 2020 – Dec. 2020 | Manager, Data Center Dept., Big Data Business Team, Jan. 2019 – Dec. 2019 | Manager, Water Data Collection and Analysis Dept., Water Data Integration Team, Jan. 2018 – Dec. 2018 | Manager, Human Resources Management Dept., HR Management Team, Jan. 2013 – Dec. 2017 | Staff, Information System Management Dept., Information Planning Team, Jul. 2010 – Dec. 2012 | . | . Honors and Awards . 1st Place Prize, 5th Bigdata analysis competition in K-water, Oct. 2021 . | Academic Conference Paper Award, Korean Society of Environmental Engineering Annual Conference, Nov. 2020 . | Bronze Award, ACM-ICPC (International Collegiate Programming Contest) Asia-Seoul Regional, Nov. 2003 . | . Certification . Advanced Data Analytics Professional, certificated by K-Data, Korea, Apr. 2019 (pass rate: 2.76%) | . Professional Skills . Programming Languages : Python, R, C/C++, JAVA, ABAP (SAP) . | Data Science and Machine Learning : Keras, Tensorflow, Sci-kit Learn . | Visualization : Matplotlib, Plotly, Leaflet, QGIS, OpenGL . | .",
          "url": "https://hyunholee26.github.io/fastpages/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://hyunholee26.github.io/fastpages/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}